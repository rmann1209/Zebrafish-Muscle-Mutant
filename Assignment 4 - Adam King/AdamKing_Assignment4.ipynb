{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, roc_auc_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.mixture import GaussianMixture\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats\n",
    "import seaborn as sns\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from scipy.stats import pearsonr\n",
    "import scipy.cluster.hierarchy as sch\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the TSV file\n",
    "file_path = 'ERP009868.tsv'\n",
    "expression_data = pd.read_csv(file_path, sep='\\t', index_col=0)\n",
    "\n",
    "# Load the metadata\n",
    "metadata_path = 'metadata_ERP009868.tsv'\n",
    "metadata = pd.read_csv(metadata_path, sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.99\n",
      "Confusion Matrix:\n",
      "[[ 21   3]\n",
      " [  0 354]]\n"
     ]
    }
   ],
   "source": [
    "# Part A)\n",
    "# Subset to the 5,000 most variable genes\n",
    "var_genes = expression_data.std(axis=1).sort_values(ascending=False).head(5000).index\n",
    "expression_subset = expression_data.loc[var_genes]\n",
    "\n",
    "# Part B)\n",
    "# Use Random Forest to separate between mutations and normal\n",
    "\n",
    "# Create a dictionary to map sample names to their group\n",
    "sample_to_group = {}\n",
    "for _, row in metadata.iterrows():\n",
    "    sample_name = row['refinebio_accession_code']\n",
    "    if row['refinebio_title'] == \"Danio rerio\":\n",
    "        sample_to_group[sample_name] = 'reference'\n",
    "    else:\n",
    "        sample_to_group[sample_name] = 'mutated'\n",
    "\n",
    "# Subset the expression data to the samples with known group labels\n",
    "X = expression_data.T\n",
    "y = [sample_to_group[sample] for sample in X.index]\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the random forest classifier\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = rf.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(f'Accuracy: {accuracy:.2f}')\n",
    "print('Confusion Matrix:')\n",
    "print(conf_matrix)\n",
    "\n",
    "results = pd.DataFrame({'Actual Group': y_test, 'Predicted Group': y_pred})\n",
    "results.to_csv('rf_predictions.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.00\n",
      "Confusion Matrix:\n",
      "[[360   0]\n",
      " [  1  17]]\n"
     ]
    }
   ],
   "source": [
    "# Part E)\n",
    "# Run Gaussian Mixture Models from previous assignment\n",
    "# Run Gaussian Mixture Models\n",
    "scaler = MinMaxScaler()\n",
    "expression_scaled = scaler.fit_transform(expression_subset.T)\n",
    "\n",
    "gmm = GaussianMixture(n_components=2, random_state=42)\n",
    "gmm.fit(expression_scaled)\n",
    "gmm_labels = gmm.predict(expression_scaled)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X = expression_subset.T\n",
    "y = gmm_labels\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the random forest classifier\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = rf.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(f'Accuracy: {accuracy:.2f}')\n",
    "print('Confusion Matrix:')\n",
    "print(conf_matrix)\n",
    "\n",
    "results = pd.DataFrame({'Actual Group': y_test, 'Predicted Group': y_pred})\n",
    "results.to_csv('rf_cluster_predictions.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Group Prediction Class Counts:\n",
      "          mutant  mutated  reference\n",
      "SampleID                            \n",
      "0              0        0          4\n",
      "1              0        0          4\n",
      "2              1        0          3\n",
      "3              0        0          4\n",
      "4              0        0          4\n",
      "...          ...      ...        ...\n",
      "561            0        0          2\n",
      "562            0        0          2\n",
      "563            0        0          2\n",
      "564            0        0          2\n",
      "565            0        0          2\n",
      "\n",
      "[566 rows x 3 columns]\n",
      "\n",
      "Cluster Prediction Class Counts:\n",
      "          0.0    1.0    2.0    3.0    4.0    5.0    6.0    18.0   28.0   \\\n",
      "SampleID                                                                  \n",
      "0             3      0      0      0      0      0      0      0      0   \n",
      "1             1      0      1      0      0      0      1      0      0   \n",
      "2             3      0      0      0      0      0      0      0      0   \n",
      "3             2      0      0      0      1      0      0      0      0   \n",
      "4             2      0      0      1      0      0      0      0      0   \n",
      "...         ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
      "561           1      0      0      0      0      0      0      0      0   \n",
      "562           1      0      0      0      0      0      0      0      0   \n",
      "563           1      0      0      0      0      0      0      0      0   \n",
      "564           0      0      0      0      0      0      1      0      0   \n",
      "565           1      0      0      0      0      0      0      0      0   \n",
      "\n",
      "          30.0   ...  102.0  103.0  104.0  105.0  106.0  107.0  108.0  109.0  \\\n",
      "SampleID         ...                                                           \n",
      "0             0  ...      0      0      0      0      0      0      0      0   \n",
      "1             0  ...      0      0      0      0      0      1      0      0   \n",
      "2             0  ...      0      0      0      0      1      0      0      0   \n",
      "3             0  ...      0      0      0      0      0      0      1      0   \n",
      "4             0  ...      0      0      0      0      0      0      0      0   \n",
      "...         ...  ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
      "561           0  ...      0      0      0      0      0      0      0      0   \n",
      "562           0  ...      0      0      0      0      0      0      0      0   \n",
      "563           0  ...      0      0      0      0      0      0      0      0   \n",
      "564           0  ...      0      0      0      0      0      0      0      0   \n",
      "565           0  ...      0      0      0      0      0      0      0      0   \n",
      "\n",
      "          110.0  111.0  \n",
      "SampleID                \n",
      "0             0      0  \n",
      "1             0      0  \n",
      "2             0      0  \n",
      "3             0      0  \n",
      "4             0      0  \n",
      "...         ...    ...  \n",
      "561           0      0  \n",
      "562           0      0  \n",
      "563           0      0  \n",
      "564           0      0  \n",
      "565           0      0  \n",
      "\n",
      "[566 rows x 79 columns]\n",
      "\n",
      "Stability Correlation between Group and Cluster Predictions: 0.10297495572686352\n"
     ]
    }
   ],
   "source": [
    "# Load each prediction file with its specific column name\n",
    "def load_prediction(file_path, pred_col):\n",
    "    df = pd.read_csv(file_path)\n",
    "    if pred_col in df.columns:\n",
    "        return df[pred_col]\n",
    "    else:\n",
    "        print(f\"Warning: Column '{pred_col}' not found in {file_path}.\")\n",
    "        return None\n",
    "\n",
    "# Group prediction columns based on actual column names\n",
    "group_predictions = {\n",
    "    \"Naive Bayes (Group)\": load_prediction(\"naive_bayes_predictions.csv\", \"Predicted\"),\n",
    "    \"KNN (Group)\": load_prediction(\"knn_predictions.csv\", \"predicted\"),\n",
    "    \"Logistic Regression (Group)\": load_prediction(\"logistic_predictions.csv\", \"Predicted_Label\"),\n",
    "    \"Random Forest (Group)\": load_prediction(\"rf_predictions.csv\", \"Predicted Group\")\n",
    "}\n",
    "\n",
    "# Cluster prediction columns based on actual column names\n",
    "cluster_predictions = {\n",
    "    \"Naive Bayes (Cluster)\": load_prediction(\"naive_bayes_cluster_predictions.csv\", \"Predicted_Cluster\"),\n",
    "    \"KNN (Cluster)\": load_prediction(\"knn_cluster_predictions.csv\", \"predicted_cluster\"),\n",
    "    \"Logistic Regression (Cluster)\": load_prediction(\"logistic_cluster_predictions.csv\", \"Predicted_Label\"),\n",
    "    \"Random Forest (Cluster)\": load_prediction(\"rf_cluster_predictions.csv\", \"Predicted Group\")\n",
    "}\n",
    "\n",
    "# Filter out any None values (i.e., files without the specified column)\n",
    "group_predictions = {k: v for k, v in group_predictions.items() if v is not None}\n",
    "cluster_predictions = {k: v for k, v in cluster_predictions.items() if v is not None}\n",
    "\n",
    "# Combine group predictions into a DataFrame and calculate class counts\n",
    "if group_predictions:\n",
    "    group_matrix = pd.DataFrame(group_predictions)\n",
    "    group_matrix.index.name = 'SampleID'\n",
    "    group_class_counts = group_matrix.apply(pd.Series.value_counts, axis=1).fillna(0).astype(int)\n",
    "    group_matrix.to_csv(\"group_prediction_matrix.csv\")\n",
    "    group_class_counts.to_csv(\"group_class_counts.csv\")\n",
    "    print(\"\\nGroup Prediction Class Counts:\")\n",
    "    print(group_class_counts)\n",
    "\n",
    "# Combine cluster predictions into a DataFrame and calculate class counts\n",
    "if cluster_predictions:\n",
    "    cluster_matrix = pd.DataFrame(cluster_predictions)\n",
    "    cluster_matrix.index.name = 'SampleID'\n",
    "    cluster_class_counts = cluster_matrix.apply(pd.Series.value_counts, axis=1).fillna(0).astype(int)\n",
    "    cluster_matrix.to_csv(\"cluster_prediction_matrix.csv\")\n",
    "    cluster_class_counts.to_csv(\"cluster_class_counts.csv\")\n",
    "    print(\"\\nCluster Prediction Class Counts:\")\n",
    "    print(cluster_class_counts)\n",
    "\n",
    "# Optional: calculate correlation if both group and cluster counts are available\n",
    "if 'group_class_counts' in locals() and 'cluster_class_counts' in locals():\n",
    "    combined_counts = group_class_counts.add(cluster_class_counts, fill_value=0)\n",
    "    stability_correlation = combined_counts.corr().iloc[0, 1]\n",
    "    print(\"\\nStability Correlation between Group and Cluster Predictions:\", stability_correlation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of models predicting each class label per sample:\n",
      "SampleID   0    1    2    3    4    5    6    7    8    9    ...  556  557  \\\n",
      "mutant       0    0    1    0    0    0    1    0    0    0  ...    0    0   \n",
      "mutated      0    0    0    0    0    0    0    0    0    0  ...    0    0   \n",
      "reference    4    4    3    4    4    4    3    4    4    4  ...    2    2   \n",
      "\n",
      "SampleID   558  559  560  561  562  563  564  565  \n",
      "mutant       0    0    0    0    0    0    0    0  \n",
      "mutated      0    0    0    0    0    0    0    0  \n",
      "reference    2    2    2    2    2    2    2    2  \n",
      "\n",
      "[3 rows x 566 columns]\n",
      "\n",
      "Number of models predicting the same cluster per sample:\n",
      "SampleID  0    1    2    3    4    5    6    7    8    9    ...  556  557  \\\n",
      "0.0         3    1    3    2    2    3    2    3    3    1  ...    0    0   \n",
      "1.0         0    0    0    0    0    0    0    0    0    1  ...    0    0   \n",
      "2.0         0    1    0    0    0    0    0    0    0    0  ...    0    0   \n",
      "3.0         0    0    0    0    1    0    0    0    0    1  ...    1    1   \n",
      "4.0         0    0    0    1    0    0    1    0    0    0  ...    0    0   \n",
      "...       ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
      "107.0       0    1    0    0    0    0    0    0    0    0  ...    0    0   \n",
      "108.0       0    0    0    1    0    0    0    0    0    0  ...    0    0   \n",
      "109.0       0    0    0    0    0    0    0    0    0    0  ...    0    0   \n",
      "110.0       0    0    0    0    0    1    0    0    1    0  ...    0    0   \n",
      "111.0       0    0    0    0    0    0    0    0    0    0  ...    0    0   \n",
      "\n",
      "SampleID  558  559  560  561  562  563  564  565  \n",
      "0.0         1    1    0    1    1    1    0    1  \n",
      "1.0         0    0    0    0    0    0    0    0  \n",
      "2.0         0    0    0    0    0    0    0    0  \n",
      "3.0         0    0    1    0    0    0    0    0  \n",
      "4.0         0    0    0    0    0    0    0    0  \n",
      "...       ...  ...  ...  ...  ...  ...  ...  ...  \n",
      "107.0       0    0    0    0    0    0    0    0  \n",
      "108.0       0    0    0    0    0    0    0    0  \n",
      "109.0       0    0    0    0    0    0    0    0  \n",
      "110.0       0    0    0    0    0    0    0    0  \n",
      "111.0       0    0    0    0    0    0    0    0  \n",
      "\n",
      "[79 rows x 566 columns]\n",
      "\n",
      "Stability Correlation between Group and Cluster Predictions: 1.00\n",
      "Corrected p-value: 0.0000\n",
      "The stability of the cluster and class label prediction is significantly correlated.\n"
     ]
    }
   ],
   "source": [
    "# Section a-c)\n",
    "# A. How many models predict each class label, for each sample?\n",
    "group_class_counts = group_class_counts.T\n",
    "print(\"\\nNumber of models predicting each class label per sample:\")\n",
    "print(group_class_counts)\n",
    "\n",
    "# B. How many models predict the same cluster, for each sample? \n",
    "cluster_class_counts = cluster_class_counts.T \n",
    "print(\"\\nNumber of models predicting the same cluster per sample:\")\n",
    "print(cluster_class_counts)\n",
    "\n",
    "# C. Does the stability of the cluster and class label prediction correlate?\n",
    "if 'group_class_counts' in locals() and 'cluster_class_counts' in locals():\n",
    "    # Combine the class and cluster counts into a single DataFrame\n",
    "    combined_counts = pd.concat([group_class_counts, cluster_class_counts], axis=1)\n",
    "    \n",
    "    # Calculate the Pearson correlation coefficient\n",
    "    stability_correlation, p_value = pearsonr(combined_counts.sum(axis=1), combined_counts.sum(axis=1, numeric_only=True))\n",
    "    \n",
    "    # Apply Bonferroni correction for multiple tests\n",
    "    alpha = 0.05\n",
    "    corrected_p_value = p_value * 2  # Bonferroni correction for 2 tests\n",
    "    \n",
    "    print(f\"\\nStability Correlation between Group and Cluster Predictions: {stability_correlation:.2f}\")\n",
    "    print(f\"Corrected p-value: {corrected_p_value:.4f}\")\n",
    "    \n",
    "    if corrected_p_value < alpha:\n",
    "        print(\"The stability of the cluster and class label prediction is significantly correlated.\")\n",
    "    else:\n",
    "        print(\"The stability of the cluster and class label prediction is not significantly correlated.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retraining models using 10 genes...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\adams\\miniconda3\\envs\\penis\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but GaussianNB was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\adams\\miniconda3\\envs\\penis\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but KNeighborsClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\adams\\miniconda3\\envs\\penis\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\adams\\miniconda3\\envs\\penis\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\adams\\miniconda3\\envs\\penis\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retraining models using 100 genes...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\adams\\miniconda3\\envs\\penis\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but GaussianNB was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\adams\\miniconda3\\envs\\penis\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but KNeighborsClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\adams\\miniconda3\\envs\\penis\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\adams\\miniconda3\\envs\\penis\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\adams\\miniconda3\\envs\\penis\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retraining models using 1000 genes...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\adams\\miniconda3\\envs\\penis\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but GaussianNB was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\adams\\miniconda3\\envs\\penis\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but KNeighborsClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\adams\\miniconda3\\envs\\penis\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\adams\\miniconda3\\envs\\penis\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\adams\\miniconda3\\envs\\penis\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retraining models using 10000 genes...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\adams\\miniconda3\\envs\\penis\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but GaussianNB was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\adams\\miniconda3\\envs\\penis\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but KNeighborsClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\adams\\miniconda3\\envs\\penis\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\adams\\miniconda3\\envs\\penis\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Analysis of how the number of genes affected the results:\n",
      "Using 10 genes:\n",
      "Group Prediction AUC:\n",
      "{'Naive Bayes (Group)': np.float64(0.9791666666666667), 'KNN (Group)': np.float64(0.8875), 'Logistic Regression (Group)': np.float64(0.8583333333333334), 'Random Forest (Group)': np.float64(0.9722222222222222)}\n",
      "Cluster Prediction AUC:\n",
      "{'Naive Bayes (Cluster)': np.float64(0.5), 'KNN (Cluster)': np.float64(0.5), 'Logistic Regression (Cluster)': np.float64(0.8828053898270807), 'Random Forest (Cluster)': np.float64(0.5)}\n",
      "\n",
      "Using 100 genes:\n",
      "Group Prediction AUC:\n",
      "{'Naive Bayes (Group)': np.float64(0.9791666666666667), 'KNN (Group)': np.float64(0.8875), 'Logistic Regression (Group)': np.float64(0.8583333333333334), 'Random Forest (Group)': np.float64(0.9722222222222222)}\n",
      "Cluster Prediction AUC:\n",
      "{'Naive Bayes (Cluster)': np.float64(0.5), 'KNN (Cluster)': np.float64(0.5), 'Logistic Regression (Cluster)': np.float64(0.8828053898270807), 'Random Forest (Cluster)': np.float64(0.5)}\n",
      "\n",
      "Using 1000 genes:\n",
      "Group Prediction AUC:\n",
      "{'Naive Bayes (Group)': np.float64(0.9791666666666667), 'KNN (Group)': np.float64(0.8875), 'Logistic Regression (Group)': np.float64(0.8583333333333334), 'Random Forest (Group)': np.float64(0.9722222222222222)}\n",
      "Cluster Prediction AUC:\n",
      "{'Naive Bayes (Cluster)': np.float64(0.5), 'KNN (Cluster)': np.float64(0.5), 'Logistic Regression (Cluster)': np.float64(0.8828053898270807), 'Random Forest (Cluster)': np.float64(0.5)}\n",
      "\n",
      "Using 10000 genes:\n",
      "Group Prediction AUC:\n",
      "{'Naive Bayes (Group)': np.float64(0.9791666666666667), 'KNN (Group)': np.float64(0.8875), 'Logistic Regression (Group)': np.float64(0.8583333333333334), 'Random Forest (Group)': np.float64(0.9722222222222222)}\n",
      "Cluster Prediction AUC:\n",
      "{'Naive Bayes (Cluster)': np.float64(0.5), 'KNN (Cluster)': np.float64(0.5), 'Logistic Regression (Cluster)': np.float64(0.8828053898270807), 'Random Forest (Cluster)': np.float64(0.5)}\n",
      "\n",
      "\n",
      "Summary of model performance (AUC) for different gene counts:\n",
      "                     10 genes (Group)  10 genes (Cluster)  100 genes (Group)  \\\n",
      "Naive Bayes                      0.98                0.50               0.98   \n",
      "KNN                              0.89                0.50               0.89   \n",
      "Logistic Regression              0.86                0.88               0.86   \n",
      "Random Forest                    0.97                0.50               0.97   \n",
      "\n",
      "                     100 genes (Cluster)  1000 genes (Group)  \\\n",
      "Naive Bayes                         0.50                0.98   \n",
      "KNN                                 0.50                0.89   \n",
      "Logistic Regression                 0.88                0.86   \n",
      "Random Forest                       0.50                0.97   \n",
      "\n",
      "                     1000 genes (Cluster)  10000 genes (Group)  \\\n",
      "Naive Bayes                          0.50                 0.98   \n",
      "KNN                                  0.50                 0.89   \n",
      "Logistic Regression                  0.88                 0.86   \n",
      "Random Forest                        0.50                 0.97   \n",
      "\n",
      "                     10000 genes (Cluster)  \n",
      "Naive Bayes                           0.50  \n",
      "KNN                                   0.50  \n",
      "Logistic Regression                   0.88  \n",
      "Random Forest                         0.50  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\adams\\miniconda3\\envs\\penis\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Retrain each predictive model using different numbers of genes\n",
    "gene_counts = [10, 100, 1000, 10000]\n",
    "auc_results = {}\n",
    "\n",
    "for gene_count in gene_counts:\n",
    "    print(f\"Retraining models using {gene_count} genes...\")\n",
    "    \n",
    "    # Subset the expression data to the top gene_count most variable genes\n",
    "    var_genes = expression_data.std(axis=1).sort_values(ascending=False).head(gene_count).index\n",
    "    expression_subset = expression_data.loc[var_genes]\n",
    "\n",
    "    # Retrain the models\n",
    "    group_predictions = {}\n",
    "    cluster_predictions = {}\n",
    "\n",
    "    # Naive Bayes\n",
    "    naive_bayes = GaussianNB()\n",
    "    naive_bayes.fit(X_train, y_train)\n",
    "    group_predictions[\"Naive Bayes (Group)\"] = naive_bayes.predict(X_test)\n",
    "    cluster_predictions[\"Naive Bayes (Cluster)\"] = naive_bayes.predict(expression_scaled)\n",
    "\n",
    "    # KNN\n",
    "    knn = KNeighborsClassifier()\n",
    "    knn.fit(X_train, y_train)\n",
    "    group_predictions[\"KNN (Group)\"] = knn.predict(X_test)\n",
    "    cluster_predictions[\"KNN (Cluster)\"] = knn.predict(expression_scaled)\n",
    "\n",
    "    # Logistic Regression\n",
    "    logreg = LogisticRegression(random_state=42)\n",
    "    logreg.fit(X_train, y_train)\n",
    "    group_predictions[\"Logistic Regression (Group)\"] = logreg.predict(X_test)\n",
    "    cluster_predictions[\"Logistic Regression (Cluster)\"] = logreg.predict(expression_scaled)\n",
    "\n",
    "    # Random Forest\n",
    "    rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    rf.fit(X_train, y_train)\n",
    "    group_predictions[\"Random Forest (Group)\"] = rf.predict(X_test)\n",
    "    cluster_predictions[\"Random Forest (Cluster)\"] = rf.predict(expression_scaled)\n",
    "\n",
    "    # Calculate AUC for each model\n",
    "    group_auc = {}\n",
    "    cluster_auc = {}\n",
    "\n",
    "    for model, y_pred in group_predictions.items():\n",
    "        group_auc[model] = roc_auc_score(y_test, y_pred)\n",
    "\n",
    "    for model, y_pred in cluster_predictions.items():\n",
    "        cluster_auc[model] = roc_auc_score(gmm_labels, y_pred)\n",
    "\n",
    "    auc_results[gene_count] = {\n",
    "        \"Group\": group_auc,\n",
    "        \"Cluster\": cluster_auc\n",
    "    }\n",
    "\n",
    "# a. How did the number of genes affect the results?\n",
    "print(\"\\nAnalysis of how the number of genes affected the results:\")\n",
    "for gene_count, results in auc_results.items():\n",
    "    print(f\"Using {gene_count} genes:\")\n",
    "    print(\"Group Prediction AUC:\")\n",
    "    print(results[\"Group\"])\n",
    "    print(\"Cluster Prediction AUC:\")\n",
    "    print(results[\"Cluster\"])\n",
    "    print()\n",
    "\n",
    "# b. What is the model performance (AUC) for each of the different versions of the model? \n",
    "# Does it increase or decrease as the number of genes included in the model changes?\n",
    "print(\"\\nSummary of model performance (AUC) for different gene counts:\")\n",
    "model_performance = pd.DataFrame(index=[\"Naive Bayes\", \"KNN\", \"Logistic Regression\", \"Random Forest\"])\n",
    "for gene_count, results in auc_results.items():\n",
    "    model_performance[f\"{gene_count} genes (Group)\"] = [results[\"Group\"][f\"Naive Bayes (Group)\"],\n",
    "                                                       results[\"Group\"][f\"KNN (Group)\"],\n",
    "                                                       results[\"Group\"][f\"Logistic Regression (Group)\"],\n",
    "                                                       results[\"Group\"][f\"Random Forest (Group)\"]]\n",
    "    model_performance[f\"{gene_count} genes (Cluster)\"] = [results[\"Cluster\"][f\"Naive Bayes (Cluster)\"],\n",
    "                                                         results[\"Cluster\"][f\"KNN (Cluster)\"],\n",
    "                                                         results[\"Cluster\"][f\"Logistic Regression (Cluster)\"],\n",
    "                                                         results[\"Cluster\"][f\"Random Forest (Cluster)\"]]\n",
    "\n",
    "print(model_performance.round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\adams\\miniconda3\\envs\\penis\\Lib\\site-packages\\seaborn\\matrix.py:560: UserWarning: Clustering large matrix with scipy. Installing `fastcluster` may give better performance.\n",
      "  warnings.warn(msg)\n",
      "c:\\Users\\adams\\miniconda3\\envs\\penis\\Lib\\site-packages\\seaborn\\matrix.py:560: UserWarning: Clustering large matrix with scipy. Installing `fastcluster` may give better performance.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Heatmap Generation Summary:\n",
      "Total number of genes: 10000\n",
      "Number of samples: 1886\n",
      "\n",
      "Sample group counts:\n",
      "reference: 1766\n",
      "mutated: 120\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1500x1200 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load the expression data\n",
    "expression_data = pd.read_csv('ERP009868.tsv', sep='\\t', index_col=0)\n",
    "\n",
    "# Load the metadata\n",
    "metadata = pd.read_csv('metadata_ERP009868.tsv', sep='\\t')\n",
    "\n",
    "# Create a dictionary to map sample names to their group\n",
    "sample_to_group = {row['refinebio_accession_code']: 'reference' if row['refinebio_title'] == 'Danio rerio' else 'mutated' \n",
    "                   for _, row in metadata.iterrows()}\n",
    "\n",
    "# Get the most variable genes for each model size\n",
    "def get_variable_genes(data, n_genes):\n",
    "    variances = data.var(axis=1).sort_values(ascending=False)\n",
    "    return variances.head(n_genes).index.tolist()\n",
    "\n",
    "# Collect genes from different model sizes\n",
    "all_genes = []\n",
    "for n_genes in [10, 100, 1000, 10000]:\n",
    "    genes = get_variable_genes(expression_data, n_genes)\n",
    "    all_genes.extend(genes)\n",
    "\n",
    "# Remove duplicates while maintaining order\n",
    "all_genes = list(dict.fromkeys(all_genes))\n",
    "\n",
    "# Create expression matrix for selected genes\n",
    "log2_expression = np.log2(expression_data.loc[all_genes] + 1)\n",
    "\n",
    "# Create a color mapping\n",
    "color_map = {'reference': '#2ecc71', 'mutated': '#e74c3c'}  # Green for reference, Red for mutated\n",
    "\n",
    "# Create a color list for the columns\n",
    "col_colors = [color_map[sample_to_group[sample]] for sample in log2_expression.columns]\n",
    "\n",
    "# Create the main figure\n",
    "plt.figure(figsize=(15, 12))\n",
    "\n",
    "# Plot the heatmap with dendrograms and side color bar\n",
    "g = sns.clustermap(log2_expression, \n",
    "                   cmap='RdBu_r',\n",
    "                   col_colors=col_colors,\n",
    "                   col_cluster=True,  # Enable column clustering\n",
    "                   row_cluster=True,  # Enable row clustering\n",
    "                   cbar_kws={'label': 'Log2 Expression'},\n",
    "                   yticklabels=True,\n",
    "                   xticklabels=True,\n",
    "                   dendrogram_ratio=(.1, .2),\n",
    "                   figsize=(15, 12))\n",
    "\n",
    "# Rotate x-axis labels\n",
    "plt.setp(g.ax_heatmap.get_xticklabels(), rotation=45, ha='right')\n",
    "\n",
    "# Add a legend\n",
    "legend_elements = [plt.Rectangle((0,0), 1, 1, facecolor=color_map[label], label=label.capitalize())\n",
    "                  for label in color_map]\n",
    "g.fig.legend(handles=legend_elements,\n",
    "            title='Sample Groups',\n",
    "            loc='center left',\n",
    "            bbox_to_anchor=(1, 0.5))\n",
    "\n",
    "# Set the title\n",
    "g.fig.suptitle('Gene Expression Heatmap of Predictive Modeling Signatures', \n",
    "               fontsize=16, y=1.02)\n",
    "\n",
    "# Add axis labels\n",
    "g.ax_heatmap.set_xlabel('Samples', fontsize=12)\n",
    "g.ax_heatmap.set_ylabel('Genes', fontsize=12)\n",
    "\n",
    "# Adjust the layout and save the figure\n",
    "plt.tight_layout()\n",
    "plt.savefig('predictive_signatures_heatmap.png', dpi=300, bbox_inches='tight')\n",
    "plt.close()\n",
    "\n",
    "# Print summary statistics\n",
    "print('\\nHeatmap Generation Summary:')\n",
    "print(f\"Total number of genes: {len(all_genes)}\")\n",
    "print(f\"Number of samples: {log2_expression.shape[1]}\")\n",
    "print(\"\\nSample group counts:\")\n",
    "group_counts = pd.Series(sample_to_group.values()).value_counts()\n",
    "for group, count in group_counts.items():\n",
    "    print(f\"{group}: {count}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "penis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
