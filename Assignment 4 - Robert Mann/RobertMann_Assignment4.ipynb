{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, roc_auc_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.mixture import GaussianMixture\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats\n",
    "import seaborn as sns\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from scipy.stats import pearsonr\n",
    "import scipy.cluster.hierarchy as sch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Gene   ERR1046065   ERR1046066   ERR1046067   ERR1046068  \\\n",
      "0  ENSDARG00000000001     0.000000     1.882786     0.970794     0.000000   \n",
      "1  ENSDARG00000000002   108.934780   171.447810   153.786990   153.121580   \n",
      "2  ENSDARG00000000018   151.847600   118.113464   133.184840   191.133770   \n",
      "3  ENSDARG00000000019  2552.638200  1639.096300  1813.370100  1666.400300   \n",
      "4  ENSDARG00000000068     3.655305     4.331904     3.624755     6.494877   \n",
      "\n",
      "    ERR1046069   ERR1046070   ERR1046071   ERR1046072   ERR1046073  ...  \\\n",
      "0     0.984327     0.000000     0.000000     0.967930     0.000000  ...   \n",
      "1   153.099240    76.990480   216.064210   206.836320    96.608505  ...   \n",
      "2   132.907530   154.294390   179.296080   224.272670   190.119830  ...   \n",
      "3  1432.987900  1029.325000  1830.156700  1900.549700  1884.948700  ...   \n",
      "4     5.328189     3.728846     4.406043     2.764331     0.947352  ...   \n",
      "\n",
      "    ERR999562   ERR999563   ERR999564   ERR999565   ERR999566  ERR999567  \\\n",
      "0    0.000000    0.000000    0.000000    0.000000    0.000000    0.00000   \n",
      "1   33.736187   17.975594   12.015097   45.485016   39.948080   39.82091   \n",
      "2   14.864696   12.821579   13.661735   20.078491   18.863470   51.63534   \n",
      "3  185.857160  154.335110  105.531110  205.613100  210.780060  257.12850   \n",
      "4    0.969957    0.951556    0.000000    2.100930    1.013324    0.00000   \n",
      "\n",
      "    ERR999568   ERR999569   ERR999570  ERR999571  \n",
      "0    0.000000    1.173622    0.000000   0.000000  \n",
      "1   37.161327   24.797861   47.320350  21.394804  \n",
      "2   30.072142   17.157717   20.216757   7.426439  \n",
      "3  192.112440  145.639770  224.836670  96.101660  \n",
      "4    2.145797    1.303937    2.351865   0.000000  \n",
      "\n",
      "[5 rows x 1887 columns]\n",
      "  refinebio_accession_code experiment_accession  refinebio_age  \\\n",
      "0               ERR1046065            ERP009868            NaN   \n",
      "1               ERR1046066            ERP009868            NaN   \n",
      "2               ERR1046067            ERP009868            NaN   \n",
      "3               ERR1046068            ERP009868            NaN   \n",
      "4               ERR1046069            ERP009868            NaN   \n",
      "\n",
      "   refinebio_cell_line  refinebio_compound  refinebio_developmental_stage  \\\n",
      "0                  NaN                 NaN                            NaN   \n",
      "1                  NaN                 NaN                            NaN   \n",
      "2                  NaN                 NaN                            NaN   \n",
      "3                  NaN                 NaN                            NaN   \n",
      "4                  NaN                 NaN                            NaN   \n",
      "\n",
      "   refinebio_disease  refinebio_disease_stage  refinebio_genetic_information  \\\n",
      "0                NaN                      NaN                            NaN   \n",
      "1                NaN                      NaN                            NaN   \n",
      "2                NaN                      NaN                            NaN   \n",
      "3                NaN                      NaN                            NaN   \n",
      "4                NaN                      NaN                            NaN   \n",
      "\n",
      "  refinebio_organism  ... refinebio_processor_version  refinebio_race  \\\n",
      "0        DANIO_RERIO  ...             v1.22.12-hotfix             NaN   \n",
      "1        DANIO_RERIO  ...             v1.22.12-hotfix             NaN   \n",
      "2        DANIO_RERIO  ...             v1.22.12-hotfix             NaN   \n",
      "3        DANIO_RERIO  ...             v1.22.12-hotfix             NaN   \n",
      "4        DANIO_RERIO  ...             v1.22.12-hotfix             NaN   \n",
      "\n",
      "   refinebio_sex refinebio_source_archive_url refinebio_source_database  \\\n",
      "0            NaN                          NaN                       SRA   \n",
      "1            NaN                          NaN                       SRA   \n",
      "2            NaN                          NaN                       SRA   \n",
      "3            NaN                          NaN                       SRA   \n",
      "4            NaN                          NaN                       SRA   \n",
      "\n",
      "   refinebio_specimen_part  refinebio_subject  refinebio_time refinebio_title  \\\n",
      "0                      NaN                NaN             NaN     Danio rerio   \n",
      "1                      NaN                NaN             NaN     Danio rerio   \n",
      "2                      NaN                NaN             NaN     Danio rerio   \n",
      "3                      NaN                NaN             NaN     Danio rerio   \n",
      "4                      NaN                NaN             NaN     Danio rerio   \n",
      "\n",
      "   refinebio_treatment  \n",
      "0                  NaN  \n",
      "1                  NaN  \n",
      "2                  NaN  \n",
      "3                  NaN  \n",
      "4                  NaN  \n",
      "\n",
      "[5 rows x 24 columns]\n"
     ]
    }
   ],
   "source": [
    "expression_data = pd.read_csv('ERP009868.tsv', sep='\\t')\n",
    "metadata = pd.read_csv('metadata_ERP009868.tsv', sep='\\t')\n",
    "\n",
    "print(expression_data.head())\n",
    "print(metadata.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Gene', 'ERR1046065', 'ERR1046066', 'ERR1046067', 'ERR1046068',\n",
      "       'ERR1046069', 'ERR1046070', 'ERR1046071', 'ERR1046072', 'ERR1046073',\n",
      "       ...\n",
      "       'ERR999562', 'ERR999563', 'ERR999564', 'ERR999565', 'ERR999566',\n",
      "       'ERR999567', 'ERR999568', 'ERR999569', 'ERR999570', 'ERR999571'],\n",
      "      dtype='object', length=1887)\n",
      "Index(['refinebio_accession_code', 'experiment_accession', 'refinebio_age',\n",
      "       'refinebio_cell_line', 'refinebio_compound',\n",
      "       'refinebio_developmental_stage', 'refinebio_disease',\n",
      "       'refinebio_disease_stage', 'refinebio_genetic_information',\n",
      "       'refinebio_organism', 'refinebio_platform', 'refinebio_processed',\n",
      "       'refinebio_processor_id', 'refinebio_processor_name',\n",
      "       'refinebio_processor_version', 'refinebio_race', 'refinebio_sex',\n",
      "       'refinebio_source_archive_url', 'refinebio_source_database',\n",
      "       'refinebio_specimen_part', 'refinebio_subject', 'refinebio_time',\n",
      "       'refinebio_title', 'refinebio_treatment'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(expression_data.columns)\n",
    "print(metadata.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gene           object\n",
      "ERR1046065    float64\n",
      "ERR1046066    float64\n",
      "ERR1046067    float64\n",
      "ERR1046068    float64\n",
      "               ...   \n",
      "ERR999567     float64\n",
      "ERR999568     float64\n",
      "ERR999569     float64\n",
      "ERR999570     float64\n",
      "ERR999571     float64\n",
      "Length: 1887, dtype: object\n",
      "K-Nearest Neighbors Accuracy: 0.99\n"
     ]
    }
   ],
   "source": [
    "# Part A - D\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load the data\n",
    "expression_data = pd.read_csv('ERP009868.tsv', sep='\\t')\n",
    "metadata = pd.read_csv('metadata_ERP009868.tsv', sep='\\t')\n",
    "\n",
    "# Check the data types of the expression_data columns\n",
    "print(expression_data.dtypes)\n",
    "\n",
    "# Convert non-numeric columns to numeric\n",
    "expression_data = expression_data.select_dtypes(include=['number']).copy()\n",
    "\n",
    "# Subset to the 5,000 most variable genes\n",
    "var_genes = expression_data.std(axis=1).sort_values(ascending=False).head(5000).index\n",
    "expression_subset = expression_data.loc[var_genes]\n",
    "\n",
    "# Create a dictionary to map sample names to their group\n",
    "sample_to_group = {}\n",
    "for _, row in metadata.iterrows():\n",
    "    sample_name = row['refinebio_accession_code']\n",
    "    if row['refinebio_title'] == \"Danio rerio\":\n",
    "        sample_to_group[sample_name] = 'reference'\n",
    "    else:\n",
    "        sample_to_group[sample_name] = 'mutated'\n",
    "\n",
    "# Subset the expression data to the samples with known group labels\n",
    "X = expression_subset.T\n",
    "y = [sample_to_group[sample] for sample in X.index]\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Run K-Nearest Neighbors\n",
    "knn = KNeighborsClassifier()\n",
    "knn.fit(X_train, y_train)\n",
    "knn_score = knn.score(X_test, y_test)\n",
    "print(f'K-Nearest Neighbors Accuracy: {knn_score:.2f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "First few predictions:\n",
      "            predicted     actual\n",
      "ERR1122721  reference  reference\n",
      "ERR1122796  reference  reference\n",
      "ERR1204256  reference  reference\n",
      "ERR999427   reference  reference\n",
      "ERR1216370  reference  reference\n"
     ]
    }
   ],
   "source": [
    "# Get predictions for test set\n",
    "y_pred = knn.predict(X_test)\n",
    "\n",
    "# Create a DataFrame with the predictions and actual values\n",
    "results_df = pd.DataFrame({\n",
    "    'predicted': y_pred,\n",
    "    'actual': y_test\n",
    "}, index=X_test.index)\n",
    "\n",
    "# Save to CSV file\n",
    "results_df.to_csv('knn_predictions.csv')\n",
    "\n",
    "# Optional: Display first few rows of the results\n",
    "print(\"\\nFirst few predictions:\")\n",
    "print(results_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rmann\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\manifold\\_spectral_embedding.py:329: UserWarning: Graph is not fully connected, spectral embedding may not work as expected.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rmann\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\manifold\\_spectral_embedding.py:329: UserWarning: Graph is not fully connected, spectral embedding may not work as expected.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rmann\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\manifold\\_spectral_embedding.py:329: UserWarning: Graph is not fully connected, spectral embedding may not work as expected.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rmann\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\manifold\\_spectral_embedding.py:329: UserWarning: Graph is not fully connected, spectral embedding may not work as expected.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rmann\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\manifold\\_spectral_embedding.py:329: UserWarning: Graph is not fully connected, spectral embedding may not work as expected.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rmann\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\manifold\\_spectral_embedding.py:329: UserWarning: Graph is not fully connected, spectral embedding may not work as expected.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rmann\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\manifold\\_spectral_embedding.py:329: UserWarning: Graph is not fully connected, spectral embedding may not work as expected.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rmann\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\manifold\\_spectral_embedding.py:329: UserWarning: Graph is not fully connected, spectral embedding may not work as expected.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rmann\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\manifold\\_spectral_embedding.py:329: UserWarning: Graph is not fully connected, spectral embedding may not work as expected.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-Nearest Neighbors Accuracy (Spectral Clusters): 0.97\n"
     ]
    }
   ],
   "source": [
    "# Part E\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import SpectralClustering\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaled_data = scaler.fit_transform(expression_subset.T)\n",
    "\n",
    "# Range of cluster numbers to test\n",
    "k_values = range(2, 11)\n",
    "results = {}\n",
    "\n",
    "for n_clusters in k_values:\n",
    "    spectral = SpectralClustering(n_clusters=n_clusters, affinity='nearest_neighbors', random_state=42)\n",
    "    clusters = spectral.fit_predict(scaled_data)\n",
    "    results[n_clusters] = clusters\n",
    "\n",
    "# Select the number of clusters based on the results\n",
    "selected_k = 5\n",
    "\n",
    "# Retrain the K-Nearest Neighbors model to predict the clusters\n",
    "X = expression_subset.T\n",
    "y = results[selected_k]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "knn = KNeighborsClassifier()\n",
    "knn.fit(X_train, y_train)\n",
    "knn_score = knn.score(X_test, y_test)\n",
    "print(f'K-Nearest Neighbors Accuracy (Spectral Clusters): {knn_score:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "First few cluster predictions:\n",
      "            predicted_cluster  actual_cluster\n",
      "ERR1122721                  0               0\n",
      "ERR1122796                  2               0\n",
      "ERR1204256                  0               0\n",
      "ERR999427                   4               4\n",
      "ERR1216370                  0               0\n"
     ]
    }
   ],
   "source": [
    "# Get predictions for test set\n",
    "y_pred = knn.predict(X_test)\n",
    "\n",
    "# Create a DataFrame with the predictions and actual cluster labels\n",
    "cluster_results_df = pd.DataFrame({\n",
    "    'predicted_cluster': y_pred,\n",
    "    'actual_cluster': y_test\n",
    "}, index=X_test.index)\n",
    "\n",
    "# Save to CSV file\n",
    "cluster_results_df.to_csv('knn_cluster_predictions.csv')\n",
    "\n",
    "# Optional: Display first few rows of the results\n",
    "print(\"\\nFirst few cluster predictions:\")\n",
    "print(cluster_results_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Summary Statistics:\n",
      "Average Binary AUC: 0.989\n",
      "Average Cluster AUC: 0.968\n",
      "\n",
      "First few rows of sample-specific analysis:\n",
      "            cluster_0_count  cluster_1_count  cluster_2_count  \\\n",
      "ERR1122721                1                0                0   \n",
      "ERR1122796                0                0                1   \n",
      "ERR1204256                1                0                0   \n",
      "ERR999427                 0                0                0   \n",
      "ERR1216370                1                0                0   \n",
      "\n",
      "            cluster_3_count  cluster_4_count  binary_correct  cluster_correct  \\\n",
      "ERR1122721                0                0               1                1   \n",
      "ERR1122796                0                0               1                0   \n",
      "ERR1204256                0                0               1                1   \n",
      "ERR999427                 0                1               1                1   \n",
      "ERR1216370                0                0               1                1   \n",
      "\n",
      "            binary_auc  cluster_auc  reference_count  mutated_count  \n",
      "ERR1122721           1            1                1              0  \n",
      "ERR1122796           1            0                1              0  \n",
      "ERR1204256           1            1                1              0  \n",
      "ERR999427            1            1                1              0  \n",
      "ERR1216370           1            1                1              0  \n"
     ]
    }
   ],
   "source": [
    "# Part A & B\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load the prediction files\n",
    "binary_predictions = pd.read_csv('knn_predictions.csv', index_col=0)\n",
    "cluster_predictions = pd.read_csv('knn_cluster_predictions.csv', index_col=0)\n",
    "\n",
    "# Create a combined matrix of all predictions\n",
    "predictions_matrix = pd.DataFrame({\n",
    "    'binary_pred': binary_predictions['predicted'],\n",
    "    'binary_actual': binary_predictions['actual'],\n",
    "    'cluster_pred': cluster_predictions['predicted_cluster'],\n",
    "    'cluster_actual': cluster_predictions['actual_cluster']\n",
    "})\n",
    "\n",
    "# Initialize DataFrame to store results\n",
    "sample_analysis = pd.DataFrame(index=predictions_matrix.index)\n",
    "\n",
    "# a. Count predictions for each class label\n",
    "# For binary classification (reference/mutated)\n",
    "binary_counts = pd.DataFrame({\n",
    "    'reference_count': (predictions_matrix['binary_pred'] == 'reference').astype(int),\n",
    "    'mutated_count': (predictions_matrix['binary_pred'] == 'mutated').astype(int)\n",
    "})\n",
    "\n",
    "# For cluster classification (0-4)\n",
    "for cluster in range(5):  # since selected_k = 5\n",
    "    sample_analysis[f'cluster_{cluster}_count'] = (predictions_matrix['cluster_pred'] == cluster).astype(int)\n",
    "\n",
    "# b. Count models predicting the same label/cluster\n",
    "sample_analysis['binary_correct'] = (predictions_matrix['binary_pred'] == predictions_matrix['binary_actual']).astype(int)\n",
    "sample_analysis['cluster_correct'] = (predictions_matrix['cluster_pred'] == predictions_matrix['cluster_actual']).astype(int)\n",
    "\n",
    "# Calculate AUC (in this case, accuracy per sample)\n",
    "sample_analysis['binary_auc'] = sample_analysis['binary_correct']\n",
    "sample_analysis['cluster_auc'] = sample_analysis['cluster_correct']\n",
    "\n",
    "# Add binary counts to final DataFrame\n",
    "sample_analysis = pd.concat([sample_analysis, binary_counts], axis=1)\n",
    "\n",
    "# Save results\n",
    "sample_analysis.to_csv('sample_specific_auc.csv')\n",
    "\n",
    "# Print summary statistics\n",
    "print(\"\\nSummary Statistics:\")\n",
    "print(f\"Average Binary AUC: {sample_analysis['binary_auc'].mean():.3f}\")\n",
    "print(f\"Average Cluster AUC: {sample_analysis['cluster_auc'].mean():.3f}\")\n",
    "\n",
    "# Print first few rows of the detailed analysis\n",
    "print(\"\\nFirst few rows of sample-specific analysis:\")\n",
    "print(sample_analysis.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Correlation Analysis Results:\n",
      "       Test  Correlation  Original_P_value  Adjusted_P_value  Significant\n",
      "0   Pearson     0.276208      4.791801e-08      4.791801e-08         True\n",
      "1  Spearman     0.276208      4.791801e-08      4.791801e-08         True\n",
      "\n",
      "Interpretation:\n",
      "\n",
      "Pearson correlation:\n",
      "Correlation coefficient: 0.276\n",
      "Adjusted p-value: 4.792e-08\n",
      "Statistically significant: True\n",
      "\n",
      "Spearman correlation:\n",
      "Correlation coefficient: 0.276\n",
      "Adjusted p-value: 4.792e-08\n",
      "Statistically significant: True\n"
     ]
    }
   ],
   "source": [
    "# Part c\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "\n",
    "# Load the sample-specific analysis file\n",
    "sample_analysis = pd.read_csv('sample_specific_auc.csv', index_col=0)\n",
    "\n",
    "# Calculate correlation tests\n",
    "# 1. Pearson correlation\n",
    "pearson_corr, pearson_pval = stats.pearsonr(\n",
    "    sample_analysis['binary_auc'],\n",
    "    sample_analysis['cluster_auc']\n",
    ")\n",
    "\n",
    "# 2. Spearman correlation\n",
    "spearman_corr, spearman_pval = stats.spearmanr(\n",
    "    sample_analysis['binary_auc'],\n",
    "    sample_analysis['cluster_auc']\n",
    ")\n",
    "\n",
    "# Create array of p-values for multiple test correction\n",
    "pvalues = np.array([pearson_pval, spearman_pval])\n",
    "\n",
    "# Perform multiple test correction using Benjamini-Hochberg method\n",
    "rejected, pvalues_corrected, _, _ = multipletests(pvalues, method='fdr_bh')\n",
    "\n",
    "# Create results DataFrame\n",
    "correlation_results = pd.DataFrame({\n",
    "    'Test': ['Pearson', 'Spearman'],\n",
    "    'Correlation': [pearson_corr, spearman_corr],\n",
    "    'Original_P_value': pvalues,\n",
    "    'Adjusted_P_value': pvalues_corrected,\n",
    "    'Significant': rejected\n",
    "})\n",
    "\n",
    "# Save correlation results\n",
    "correlation_results.to_csv('correlation_results.csv')\n",
    "\n",
    "# Print results\n",
    "print(\"\\nCorrelation Analysis Results:\")\n",
    "print(correlation_results)\n",
    "\n",
    "# Optional: Create a scatter plot to visualize the correlation\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(sample_analysis['binary_auc'], sample_analysis['cluster_auc'], alpha=0.5)\n",
    "plt.xlabel('Binary Classification AUC')\n",
    "plt.ylabel('Cluster Classification AUC')\n",
    "plt.title('Correlation between Binary and Cluster Prediction Stability')\n",
    "plt.savefig('correlation_plot.png')\n",
    "plt.close()\n",
    "\n",
    "# Print interpretation\n",
    "print(\"\\nInterpretation:\")\n",
    "for idx, row in correlation_results.iterrows():\n",
    "    print(f\"\\n{row['Test']} correlation:\")\n",
    "    print(f\"Correlation coefficient: {row['Correlation']:.3f}\")\n",
    "    print(f\"Adjusted p-value: {row['Adjusted_P_value']:.3e}\")\n",
    "    print(f\"Statistically significant: {row['Significant']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Group Prediction Class Counts:\n",
      "          mutant  mutated  reference\n",
      "SampleID                            \n",
      "0              0        0          4\n",
      "1              0        0          4\n",
      "2              1        0          3\n",
      "3              0        0          4\n",
      "4              0        0          4\n",
      "...          ...      ...        ...\n",
      "561            0        0          2\n",
      "562            0        0          2\n",
      "563            0        0          2\n",
      "564            0        0          2\n",
      "565            0        0          2\n",
      "\n",
      "[566 rows x 3 columns]\n",
      "\n",
      "Cluster Prediction Class Counts:\n",
      "          0.0    1.0    2.0    3.0    4.0    5.0    6.0    18.0   28.0   \\\n",
      "SampleID                                                                  \n",
      "0             3      0      0      0      0      0      0      0      0   \n",
      "1             1      0      1      0      0      0      1      0      0   \n",
      "2             3      0      0      0      0      0      0      0      0   \n",
      "3             2      0      0      0      1      0      0      0      0   \n",
      "4             2      0      0      1      0      0      0      0      0   \n",
      "...         ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
      "561           1      0      0      0      0      0      0      0      0   \n",
      "562           1      0      0      0      0      0      0      0      0   \n",
      "563           1      0      0      0      0      0      0      0      0   \n",
      "564           0      0      0      0      0      0      1      0      0   \n",
      "565           1      0      0      0      0      0      0      0      0   \n",
      "\n",
      "          30.0   ...  102.0  103.0  104.0  105.0  106.0  107.0  108.0  109.0  \\\n",
      "SampleID         ...                                                           \n",
      "0             0  ...      0      0      0      0      0      0      0      0   \n",
      "1             0  ...      0      0      0      0      0      1      0      0   \n",
      "2             0  ...      0      0      0      0      1      0      0      0   \n",
      "3             0  ...      0      0      0      0      0      0      1      0   \n",
      "4             0  ...      0      0      0      0      0      0      0      0   \n",
      "...         ...  ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
      "561           0  ...      0      0      0      0      0      0      0      0   \n",
      "562           0  ...      0      0      0      0      0      0      0      0   \n",
      "563           0  ...      0      0      0      0      0      0      0      0   \n",
      "564           0  ...      0      0      0      0      0      0      0      0   \n",
      "565           0  ...      0      0      0      0      0      0      0      0   \n",
      "\n",
      "          110.0  111.0  \n",
      "SampleID                \n",
      "0             0      0  \n",
      "1             0      0  \n",
      "2             0      0  \n",
      "3             0      0  \n",
      "4             0      0  \n",
      "...         ...    ...  \n",
      "561           0      0  \n",
      "562           0      0  \n",
      "563           0      0  \n",
      "564           0      0  \n",
      "565           0      0  \n",
      "\n",
      "[566 rows x 79 columns]\n",
      "\n",
      "Stability Correlation between Group and Cluster Predictions: 0.10297495572686352\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load each prediction file with its specific column name\n",
    "def load_prediction(file_path, pred_col):\n",
    "    df = pd.read_csv(file_path)\n",
    "    if pred_col in df.columns:\n",
    "        return df[pred_col]\n",
    "    else:\n",
    "        print(f\"Warning: Column '{pred_col}' not found in {file_path}.\")\n",
    "        return None\n",
    "\n",
    "# Group prediction columns based on actual column names\n",
    "group_predictions = {\n",
    "    \"Naive Bayes (Group)\": load_prediction(\"naive_bayes_predictions.csv\", \"Predicted\"),\n",
    "    \"KNN (Group)\": load_prediction(\"knn_predictions.csv\", \"predicted\"),\n",
    "    \"Logistic Regression (Group)\": load_prediction(\"logistic_predictions.csv\", \"Predicted_Label\"),\n",
    "    \"Random Forest (Group)\": load_prediction(\"rf_predictions.csv\", \"Predicted Group\")\n",
    "}\n",
    "\n",
    "# Cluster prediction columns based on actual column names\n",
    "cluster_predictions = {\n",
    "    \"Naive Bayes (Cluster)\": load_prediction(\"naive_bayes_cluster_predictions.csv\", \"Predicted_Cluster\"),\n",
    "    \"KNN (Cluster)\": load_prediction(\"knn_cluster_predictions.csv\", \"predicted_cluster\"),\n",
    "    \"Logistic Regression (Cluster)\": load_prediction(\"logistic_cluster_predictions.csv\", \"Predicted_Label\"),\n",
    "    \"Random Forest (Cluster)\": load_prediction(\"rf_cluster_predictions.csv\", \"Predicted Group\")\n",
    "}\n",
    "\n",
    "# Filter out any None values (i.e., files without the specified column)\n",
    "group_predictions = {k: v for k, v in group_predictions.items() if v is not None}\n",
    "cluster_predictions = {k: v for k, v in cluster_predictions.items() if v is not None}\n",
    "\n",
    "# Combine group predictions into a DataFrame and calculate class counts\n",
    "if group_predictions:\n",
    "    group_matrix = pd.DataFrame(group_predictions)\n",
    "    group_matrix.index.name = 'SampleID'\n",
    "    group_class_counts = group_matrix.apply(pd.Series.value_counts, axis=1).fillna(0).astype(int)\n",
    "    group_matrix.to_csv(\"group_prediction_matrix.csv\")\n",
    "    group_class_counts.to_csv(\"group_class_counts.csv\")\n",
    "    print(\"\\nGroup Prediction Class Counts:\")\n",
    "    print(group_class_counts)\n",
    "\n",
    "# Combine cluster predictions into a DataFrame and calculate class counts\n",
    "if cluster_predictions:\n",
    "    cluster_matrix = pd.DataFrame(cluster_predictions)\n",
    "    cluster_matrix.index.name = 'SampleID'\n",
    "    cluster_class_counts = cluster_matrix.apply(pd.Series.value_counts, axis=1).fillna(0).astype(int)\n",
    "    cluster_matrix.to_csv(\"cluster_prediction_matrix.csv\")\n",
    "    cluster_class_counts.to_csv(\"cluster_class_counts.csv\")\n",
    "    print(\"\\nCluster Prediction Class Counts:\")\n",
    "    print(cluster_class_counts)\n",
    "\n",
    "# Optional: calculate correlation if both group and cluster counts are available\n",
    "if 'group_class_counts' in locals() and 'cluster_class_counts' in locals():\n",
    "    combined_counts = group_class_counts.add(cluster_class_counts, fill_value=0)\n",
    "    stability_correlation = combined_counts.corr().iloc[0, 1]\n",
    "    print(\"\\nStability Correlation between Group and Cluster Predictions:\", stability_correlation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of models predicting each class label per sample:\n",
      "SampleID   0    1    2    3    4    5    6    7    8    9    ...  556  557  \\\n",
      "mutant       0    0    1    0    0    0    1    0    0    0  ...    0    0   \n",
      "mutated      0    0    0    0    0    0    0    0    0    0  ...    0    0   \n",
      "reference    4    4    3    4    4    4    3    4    4    4  ...    2    2   \n",
      "\n",
      "SampleID   558  559  560  561  562  563  564  565  \n",
      "mutant       0    0    0    0    0    0    0    0  \n",
      "mutated      0    0    0    0    0    0    0    0  \n",
      "reference    2    2    2    2    2    2    2    2  \n",
      "\n",
      "[3 rows x 566 columns]\n",
      "\n",
      "Number of models predicting the same cluster per sample:\n",
      "SampleID  0    1    2    3    4    5    6    7    8    9    ...  556  557  \\\n",
      "0.0         3    1    3    2    2    3    2    3    3    1  ...    0    0   \n",
      "1.0         0    0    0    0    0    0    0    0    0    1  ...    0    0   \n",
      "2.0         0    1    0    0    0    0    0    0    0    0  ...    0    0   \n",
      "3.0         0    0    0    0    1    0    0    0    0    1  ...    1    1   \n",
      "4.0         0    0    0    1    0    0    1    0    0    0  ...    0    0   \n",
      "...       ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
      "107.0       0    1    0    0    0    0    0    0    0    0  ...    0    0   \n",
      "108.0       0    0    0    1    0    0    0    0    0    0  ...    0    0   \n",
      "109.0       0    0    0    0    0    0    0    0    0    0  ...    0    0   \n",
      "110.0       0    0    0    0    0    1    0    0    1    0  ...    0    0   \n",
      "111.0       0    0    0    0    0    0    0    0    0    0  ...    0    0   \n",
      "\n",
      "SampleID  558  559  560  561  562  563  564  565  \n",
      "0.0         1    1    0    1    1    1    0    1  \n",
      "1.0         0    0    0    0    0    0    0    0  \n",
      "2.0         0    0    0    0    0    0    0    0  \n",
      "3.0         0    0    1    0    0    0    0    0  \n",
      "4.0         0    0    0    0    0    0    0    0  \n",
      "...       ...  ...  ...  ...  ...  ...  ...  ...  \n",
      "107.0       0    0    0    0    0    0    0    0  \n",
      "108.0       0    0    0    0    0    0    0    0  \n",
      "109.0       0    0    0    0    0    0    0    0  \n",
      "110.0       0    0    0    0    0    0    0    0  \n",
      "111.0       0    0    0    0    0    0    0    0  \n",
      "\n",
      "[79 rows x 566 columns]\n",
      "\n",
      "Stability Correlation between Group and Cluster Predictions: 1.00\n",
      "Corrected p-value: 0.0000\n",
      "The stability of the cluster and class label prediction is significantly correlated.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "# Use the code from the previous artifact to get the prediction matrices\n",
    "\n",
    "# A. How many models predict each class label, for each sample?\n",
    "group_class_counts = group_class_counts.T\n",
    "print(\"\\nNumber of models predicting each class label per sample:\")\n",
    "print(group_class_counts)\n",
    "\n",
    "# B. How many models predict the same cluster, for each sample? \n",
    "cluster_class_counts = cluster_class_counts.T \n",
    "print(\"\\nNumber of models predicting the same cluster per sample:\")\n",
    "print(cluster_class_counts)\n",
    "\n",
    "# C. Does the stability of the cluster and class label prediction correlate?\n",
    "if 'group_class_counts' in locals() and 'cluster_class_counts' in locals():\n",
    "    # Combine the class and cluster counts into a single DataFrame\n",
    "    combined_counts = pd.concat([group_class_counts, cluster_class_counts], axis=1)\n",
    "    \n",
    "    # Calculate the Pearson correlation coefficient\n",
    "    stability_correlation, p_value = pearsonr(combined_counts.sum(axis=1), combined_counts.sum(axis=1, numeric_only=True))\n",
    "    \n",
    "    # Apply Bonferroni correction for multiple tests\n",
    "    alpha = 0.05\n",
    "    corrected_p_value = p_value * 2  # Bonferroni correction for 2 tests\n",
    "    \n",
    "    print(f\"\\nStability Correlation between Group and Cluster Predictions: {stability_correlation:.2f}\")\n",
    "    print(f\"Corrected p-value: {corrected_p_value:.4f}\")\n",
    "    \n",
    "    if corrected_p_value < alpha:\n",
    "        print(\"The stability of the cluster and class label prediction is significantly correlated.\")\n",
    "    else:\n",
    "        print(\"The stability of the cluster and class label prediction is not significantly correlated.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results Summary:\n",
      " n_genes  accuracy      auc\n",
      "      10  0.970899 0.990760\n",
      "     100  0.986772 0.998352\n",
      "    1000  0.989418 0.999058\n",
      "   10000  0.989418 0.999058\n",
      "\n",
      "Performance Changes:\n",
      "\n",
      "From 10 to 100 genes:\n",
      "AUC change: 0.0076\n",
      "\n",
      "From 100 to 1000 genes:\n",
      "AUC change: 0.0007\n",
      "\n",
      "From 1000 to 10000 genes:\n",
      "AUC change: 0.0000\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Convert non-numeric columns to numeric\n",
    "expression_data = expression_data.select_dtypes(include=['number']).copy()\n",
    "\n",
    "# Create sample to group mapping\n",
    "sample_to_group = {}\n",
    "for _, row in metadata.iterrows():\n",
    "    sample_name = row['refinebio_accession_code']\n",
    "    if row['refinebio_title'] == \"Danio rerio\":\n",
    "        sample_to_group[sample_name] = 'reference'\n",
    "    else:\n",
    "        sample_to_group[sample_name] = 'mutated'\n",
    "\n",
    "# Function to train model with specified number of genes\n",
    "def train_and_evaluate(n_genes):\n",
    "    # Select the n most variable genes\n",
    "    var_genes = expression_data.std(axis=1).sort_values(ascending=False).head(n_genes).index\n",
    "    expression_subset = expression_data.loc[var_genes]\n",
    "    \n",
    "    # Prepare the data\n",
    "    X = expression_subset.T\n",
    "    y = [sample_to_group[sample] for sample in X.index]\n",
    "    \n",
    "    # Split the data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Train and evaluate model\n",
    "    knn = KNeighborsClassifier()\n",
    "    knn.fit(X_train, y_train)\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    accuracy = knn.score(X_test, y_test)\n",
    "    \n",
    "    # Calculate AUC\n",
    "    y_pred_proba = knn.predict_proba(X_test)\n",
    "    y_test_binary = [1 if label == 'mutated' else 0 for label in y_test]\n",
    "    auc = roc_auc_score(y_test_binary, y_pred_proba[:, 1])\n",
    "    \n",
    "    # Save predictions\n",
    "    y_pred = knn.predict(X_test)\n",
    "    predictions_df = pd.DataFrame({\n",
    "        'predicted': y_pred,\n",
    "        'actual': y_test,\n",
    "        'prob_mutated': y_pred_proba[:, 1]\n",
    "    }, index=X_test.index)\n",
    "    predictions_df.to_csv(f'predictions_{n_genes}_genes.csv')\n",
    "    \n",
    "    return accuracy, auc\n",
    "\n",
    "# Test different numbers of genes\n",
    "gene_numbers = [10, 100, 1000, 10000]\n",
    "results = []\n",
    "\n",
    "for n_genes in gene_numbers:\n",
    "    accuracy, auc = train_and_evaluate(n_genes)\n",
    "    results.append({\n",
    "        'n_genes': n_genes,\n",
    "        'accuracy': accuracy,\n",
    "        'auc': 1 - auc\n",
    "    })\n",
    "\n",
    "# Create results DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df.to_csv('gene_number_results.csv')\n",
    "\n",
    "# Plot the results\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(results_df['n_genes'], results_df['auc'], marker='o', label='AUC')\n",
    "plt.plot(results_df['n_genes'], results_df['accuracy'], marker='s', label='Accuracy')\n",
    "plt.xscale('log')\n",
    "plt.xlabel('Number of Genes')\n",
    "plt.ylabel('Score')\n",
    "plt.title('Model Performance vs Number of Genes')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.savefig('performance_vs_genes.png')\n",
    "plt.close()\n",
    "\n",
    "# Print results\n",
    "print(\"\\nResults Summary:\")\n",
    "print(results_df.to_string(index=False))\n",
    "\n",
    "# Calculate performance changes\n",
    "print(\"\\nPerformance Changes:\")\n",
    "for i in range(1, len(gene_numbers)):\n",
    "    prev_genes = gene_numbers[i-1]\n",
    "    curr_genes = gene_numbers[i]\n",
    "    auc_change = results_df.iloc[i]['auc'] - results_df.iloc[i-1]['auc']\n",
    "    print(f\"\\nFrom {prev_genes} to {curr_genes} genes:\")\n",
    "    print(f\"AUC change: {auc_change:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating models with top 10 genes:\n",
      "Insufficient samples for 10 genes. Skipping.\n",
      "Insufficient samples for 10 genes. Skipping.\n",
      "Insufficient samples for 10 genes. Skipping.\n",
      "Insufficient samples for 10 genes. Skipping.\n",
      "\n",
      "Evaluating models with top 100 genes:\n",
      "Naive Bayes AUC for top 100 genes: 0.8571428571428572\n",
      "KNN AUC for top 100 genes: 0.9813664596273293\n",
      "Logistic Regression AUC for top 100 genes: 1.0\n",
      "Random Forest AUC for top 100 genes: 1.0\n",
      "\n",
      "Evaluating models with top 1000 genes:\n",
      "Naive Bayes AUC for top 1000 genes: 0.5943396226415094\n",
      "KNN AUC for top 1000 genes: 0.9947169811320755\n",
      "Logistic Regression AUC for top 1000 genes: 0.991266846361186\n",
      "Random Forest AUC for top 1000 genes: 1.0\n",
      "\n",
      "Evaluating models with top 10000 genes:\n",
      "Naive Bayes AUC for top 10000 genes: 0.5562368972746331\n",
      "KNN AUC for top 10000 genes: 0.9973794549266247\n",
      "Logistic Regression AUC for top 10000 genes: 1.0\n",
      "Random Forest AUC for top 10000 genes: 1.0\n",
      "\n",
      "Summary of AUC Scores by Gene Count and Model:\n",
      "       Naive Bayes       KNN  Logistic Regression  Random Forest\n",
      "100       0.857143  0.981366             1.000000            1.0\n",
      "1000      0.594340  0.994717             0.991267            1.0\n",
      "10000     0.556237  0.997379             1.000000            1.0\n"
     ]
    }
   ],
   "source": [
    "# Part 4 for everyones models combined\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load data\n",
    "expression_data = pd.read_csv('ERP009868.tsv', sep='\\t', index_col=0)\n",
    "metadata = pd.read_csv('metadata_ERP009868.tsv', sep='\\t')\n",
    "\n",
    "# Create mutation status column if it doesn't exist\n",
    "if 'mutation_status' not in metadata.columns:\n",
    "    metadata['mutation_status'] = metadata['refinebio_title'].apply(lambda x: 'reference' if x == 'Danio rerio' else 'mutant')\n",
    "\n",
    "# Define models including Adam's Random Forest\n",
    "naive_bayes_model = GaussianNB()\n",
    "knn_model = KNeighborsClassifier(n_neighbors=5)\n",
    "logistic_model = LogisticRegression(random_state=42, max_iter=1000)\n",
    "rf_model = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Store AUC scores\n",
    "auc_scores = {\n",
    "    'Naive Bayes': {},\n",
    "    'KNN': {},\n",
    "    'Logistic Regression': {},\n",
    "    'Random Forest': {}\n",
    "}\n",
    "\n",
    "# Helper function to retrain and evaluate models\n",
    "def retrain_and_evaluate(model, model_name, gene_count):\n",
    "    top_genes = expression_data.var(axis=0).nlargest(gene_count).index\n",
    "    subset_data = expression_data[top_genes].T\n",
    "    subset_data.index.name = 'refinebio_accession_code'\n",
    "    merged_data = subset_data.merge(metadata[['refinebio_accession_code', 'mutation_status']],\n",
    "                                    left_index=True,\n",
    "                                    right_on='refinebio_accession_code', how='inner')\n",
    "\n",
    "    if merged_data.empty:\n",
    "        print(f\"No matching samples for gene count {gene_count}.\")\n",
    "        return\n",
    "\n",
    "    X = merged_data.drop(columns=['refinebio_accession_code', 'mutation_status'])\n",
    "    y = merged_data['mutation_status'].apply(lambda x: 1 if x == 'mutant' else 0)\n",
    "\n",
    "    if (y.value_counts() < 2).any():\n",
    "        print(f\"Insufficient samples for {gene_count} genes. Skipping.\")\n",
    "        return\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred_proba = model.predict_proba(X_test)[:, 1] if hasattr(model, \"predict_proba\") else model.decision_function(X_test)\n",
    "    auc_score = roc_auc_score(y_test, y_pred_proba)\n",
    "    auc_scores[model_name][gene_count] = auc_score\n",
    "    print(f\"{model_name} AUC for top {gene_count} genes: {auc_score}\")\n",
    "\n",
    "# Evaluate each model\n",
    "gene_counts = [10, 100, 1000, 10000]\n",
    "for n in gene_counts:\n",
    "    print(f\"\\nEvaluating models with top {n} genes:\")\n",
    "    retrain_and_evaluate(naive_bayes_model, 'Naive Bayes', n)\n",
    "    retrain_and_evaluate(knn_model, 'KNN', n)\n",
    "    retrain_and_evaluate(logistic_model, 'Logistic Regression', n)\n",
    "    retrain_and_evaluate(rf_model, 'Random Forest', n)\n",
    "\n",
    "# Summarize AUC results\n",
    "auc_summary = pd.DataFrame(auc_scores)\n",
    "print(\"\\nSummary of AUC Scores by Gene Count and Model:\")\n",
    "print(auc_summary)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rmann\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\seaborn\\matrix.py:560: UserWarning: Clustering large matrix with scipy. Installing `fastcluster` may give better performance.\n",
      "  warnings.warn(msg)\n",
      "c:\\Users\\rmann\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\seaborn\\matrix.py:560: UserWarning: Clustering large matrix with scipy. Installing `fastcluster` may give better performance.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Heatmap Generation Summary:\n",
      "Total number of genes: 10000\n",
      "Number of samples: 1886\n",
      "\n",
      "Sample group counts:\n",
      "reference: 1766\n",
      "mutated: 120\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1500x1200 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Load the expression data\n",
    "expression_data = pd.read_csv('ERP009868.tsv', sep='\\t', index_col=0)\n",
    "\n",
    "# Load the metadata\n",
    "metadata = pd.read_csv('metadata_ERP009868.tsv', sep='\\t')\n",
    "\n",
    "# Create a dictionary to map sample names to their group\n",
    "sample_to_group = {row['refinebio_accession_code']: 'reference' if row['refinebio_title'] == 'Danio rerio' else 'mutated' \n",
    "                   for _, row in metadata.iterrows()}\n",
    "\n",
    "# Get the most variable genes for each model size\n",
    "def get_variable_genes(data, n_genes):\n",
    "    variances = data.var(axis=1).sort_values(ascending=False)\n",
    "    return variances.head(n_genes).index.tolist()\n",
    "\n",
    "# Collect genes from different model sizes\n",
    "all_genes = []\n",
    "for n_genes in [10, 100, 1000, 10000]:\n",
    "    genes = get_variable_genes(expression_data, n_genes)\n",
    "    all_genes.extend(genes)\n",
    "\n",
    "# Remove duplicates while maintaining order\n",
    "all_genes = list(dict.fromkeys(all_genes))\n",
    "\n",
    "# Create expression matrix for selected genes\n",
    "log2_expression = np.log2(expression_data.loc[all_genes] + 1)\n",
    "\n",
    "# Create a color mapping\n",
    "color_map = {'reference': '#2ecc71', 'mutated': '#e74c3c'}  # Green for reference, Red for mutated\n",
    "\n",
    "# Create a color list for the columns\n",
    "col_colors = [color_map[sample_to_group[sample]] for sample in log2_expression.columns]\n",
    "\n",
    "# Create the main figure\n",
    "plt.figure(figsize=(15, 12))\n",
    "\n",
    "# Plot the heatmap with dendrograms and side color bar\n",
    "g = sns.clustermap(log2_expression, \n",
    "                   cmap='RdBu_r',\n",
    "                   col_colors=col_colors,\n",
    "                   col_cluster=True,  # Enable column clustering\n",
    "                   row_cluster=True,  # Enable row clustering\n",
    "                   cbar_kws={'label': 'Log2 Expression'},\n",
    "                   yticklabels=True,\n",
    "                   xticklabels=True,\n",
    "                   dendrogram_ratio=(.1, .2),\n",
    "                   figsize=(15, 12))\n",
    "\n",
    "# Rotate x-axis labels\n",
    "plt.setp(g.ax_heatmap.get_xticklabels(), rotation=45, ha='right')\n",
    "\n",
    "# Add a legend\n",
    "legend_elements = [plt.Rectangle((0,0), 1, 1, facecolor=color_map[label], label=label.capitalize())\n",
    "                  for label in color_map]\n",
    "g.fig.legend(handles=legend_elements,\n",
    "            title='Sample Groups',\n",
    "            loc='center left',\n",
    "            bbox_to_anchor=(1, 0.5))\n",
    "\n",
    "# Set the title\n",
    "g.fig.suptitle('Gene Expression Heatmap of Predictive Modeling Signatures', \n",
    "               fontsize=16, y=1.02)\n",
    "\n",
    "# Add axis labels\n",
    "g.ax_heatmap.set_xlabel('Samples', fontsize=12)\n",
    "g.ax_heatmap.set_ylabel('Genes', fontsize=12)\n",
    "\n",
    "# Adjust the layout and save the figure\n",
    "plt.tight_layout()\n",
    "plt.savefig('predictive_signatures_heatmap.png', dpi=300, bbox_inches='tight')\n",
    "plt.close()\n",
    "\n",
    "# Print summary statistics\n",
    "print('\\nHeatmap Generation Summary:')\n",
    "print(f\"Total number of genes: {len(all_genes)}\")\n",
    "print(f\"Number of samples: {log2_expression.shape[1]}\")\n",
    "print(\"\\nSample group counts:\")\n",
    "group_counts = pd.Series(sample_to_group.values()).value_counts()\n",
    "for group, count in group_counts.items():\n",
    "    print(f\"{group}: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
