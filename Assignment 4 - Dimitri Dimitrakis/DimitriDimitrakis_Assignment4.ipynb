{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, roc_auc_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.mixture import GaussianMixture\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats\n",
    "import seaborn as sns\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from scipy.stats import pearsonr\n",
    "import scipy.cluster.hierarchy as sch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "\n",
    "# Load the expression data and metadata\n",
    "expression_path = 'ERP009868.tsv'\n",
    "expression_data = pd.read_csv(expression_path, sep='\\t', index_col=0)\n",
    "\n",
    "metadata_path = 'updated_metadata_ERP009868.tsv'\n",
    "metadata = pd.read_csv(metadata_path, sep='\\t', index_col=0)\n",
    "\n",
    "# Transpose the expression data to have samples as rows and genes as columns\n",
    "expression_data = expression_data.T\n",
    "\n",
    "# Calculate variances for each gene and select the top 5,000 most variable genes\n",
    "variances = expression_data.var(axis=0)\n",
    "top_genes = variances.nlargest(5000).index\n",
    "expression_data_subset = expression_data[top_genes]\n",
    "\n",
    "# Prepare metadata to merge with expression data\n",
    "expression_data_subset.index.name = 'SampleID'\n",
    "metadata_reset = metadata.reset_index().rename(columns={'refinebio_accession_code': 'SampleID'})\n",
    "\n",
    "# Merge expression data with metadata on 'SampleID'\n",
    "data = expression_data_subset.merge(metadata_reset, on='SampleID')\n",
    "\n",
    "# Create 'mutation_status' based on 'refinebio_title'\n",
    "data['mutation_status'] = data['refinebio_title'].apply(\n",
    "    lambda x: 'reference' if x == 'Danio rerio' else 'mutated'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set shape: (1320, 5000)\n",
      "Testing set shape: (566, 5000)\n",
      "Training set target distribution:\n",
      " mutation_status\n",
      "reference    1236\n",
      "mutated        84\n",
      "Name: count, dtype: int64\n",
      "Testing set target distribution:\n",
      " mutation_status\n",
      "reference    530\n",
      "mutated       36\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Separate features and target variable\n",
    "X = data[top_genes]  # Keep only gene expression columns\n",
    "y = data['mutation_status']\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
    "\n",
    "# Standardize the feature data\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Print shapes of training and testing sets to confirm setup\n",
    "print(\"Training set shape:\", X_train.shape)\n",
    "print(\"Testing set shape:\", X_test.shape)\n",
    "print(\"Training set target distribution:\\n\", y_train.value_counts())\n",
    "print(\"Testing set target distribution:\\n\", y_test.value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression model trained for predicting two groups.\n",
      "AUC Score for group prediction: 1.0\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "     mutated       1.00      1.00      1.00        36\n",
      "   reference       1.00      1.00      1.00       530\n",
      "\n",
      "    accuracy                           1.00       566\n",
      "   macro avg       1.00      1.00      1.00       566\n",
      "weighted avg       1.00      1.00      1.00       566\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, roc_auc_score, roc_curve\n",
    "\n",
    "# Initialize and train the Logistic Regression model\n",
    "logistic_model = LogisticRegression(random_state=42)\n",
    "logistic_model.fit(X_train, y_train)\n",
    "print(\"Logistic Regression model trained for predicting two groups.\")\n",
    "\n",
    "# Make predictions and evaluate the model\n",
    "y_pred = logistic_model.predict(X_test)\n",
    "y_pred_proba = logistic_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Calculate the AUC for ROC\n",
    "auc_score = roc_auc_score(y_test, y_pred_proba)\n",
    "print(\"AUC Score for group prediction:\", auc_score)\n",
    "\n",
    "# Display classification report\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster counts:\n",
      " clusters\n",
      "106    141\n",
      "110    130\n",
      "104     96\n",
      "101     82\n",
      "96      79\n",
      "      ... \n",
      "1        1\n",
      "24       1\n",
      "25       1\n",
      "26       1\n",
      "0        1\n",
      "Name: count, Length: 112, dtype: int64\n",
      "Filtered X shape: (1859, 5000)\n",
      "Filtered y_clusters shape: (1859,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression model trained for cluster prediction.\n",
      "Sample-specific AUC Scores for cluster prediction: [(0, 'AUC not defined for single-class'), (1, 'AUC not defined for single-class'), (2, 'AUC not defined for single-class'), (3, 'AUC not defined for single-class'), (4, 'AUC not defined for single-class'), (5, 'AUC not defined for single-class'), (6, 'AUC not defined for single-class'), (7, 'AUC not defined for single-class'), (8, 0.1732495511669659), (9, 'AUC not defined for single-class'), (10, 'AUC not defined for single-class'), (11, 'AUC not defined for single-class'), (12, 'AUC not defined for single-class'), (13, 'AUC not defined for single-class'), (14, 'AUC not defined for single-class'), (15, 'AUC not defined for single-class'), (16, 'AUC not defined for single-class'), (17, 'AUC not defined for single-class'), (18, 0.6609712230215827), (19, 'AUC not defined for single-class'), (20, 'AUC not defined for single-class'), (21, 'AUC not defined for single-class'), (22, 'AUC not defined for single-class'), (23, 0.2405745062836625), (24, 'AUC not defined for single-class'), (25, 'AUC not defined for single-class'), (26, 'AUC not defined for single-class'), (27, 0.42998204667863554), (28, 0.48204667863554757), (29, 0.46947935368043087), (30, 0.4766187050359712), (31, 'AUC not defined for single-class'), (32, 0.40754039497307004), (33, 0.44165170556552963), (34, 0.06104129263913827), (35, 0.4703770197486535), (36, 0.3642086330935252), (37, 0.44594594594594594), (38, 0.5467625899280575), (39, 0.3794964028776978), (40, 0.031231231231231206), (41, 0.4605026929982047), (42, 0.47833935018050544), (43, 0.01705565529622982), (44, 0.43267504488330344), (45, 0.4223826714801444), (46, 0.2252252252252252), (47, 0.3651651651651652), (48, 0.4378378378378378), (49, 0.23967684021543983), (50, 0.16876122082585276), (51, 0.06025179856115109), (52, 0.32194244604316546), (53, 0.40958408679927666), (54, 0.42072072072072075), (55, 0.3947841726618705), (56, 0.7863554757630161), (57, 0.63016157989228), (58, 0.3345323741007194), (59, 'AUC not defined for single-class'), (60, 0.3505315011667099), (61, 'AUC not defined for single-class'), (62, 0.09189189189189187), (63, 0.5687687687687687), (64, 0.27920433996383365), (65, 0.6488245931283907), (66, 0.46995772946859904), (67, 0.18454545454545457), (68, 0.14900542495479208), (69, 0.39838129496402874), (70, 0.2654611211573237), (71, 0.4787906137184116), (72, 0.4111310592459605), (73, 0.5221119133574007), (74, 0.34831005869257237), (75, 0.16876122082585276), (76, 0.1178057553956835), (77, 0.45658773527625984), (78, 0.3353572151386359), (79, 0.7073608617594255), (80, 0.58756038647343), (81, 0.4492492492492492), (82, 0.4404332129963899), (83, 0.3924050632911392), (84, 0.4544983147523982)]\n",
      "Classification Report for Cluster Prediction:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           8       0.00      0.00      0.00         1\n",
      "          18       0.50      0.50      0.50         2\n",
      "          23       0.00      0.00      0.00         1\n",
      "          27       0.00      0.00      0.00         1\n",
      "          28       0.00      0.00      0.00         1\n",
      "          29       0.00      0.00      0.00         1\n",
      "          30       0.00      0.00      0.00         2\n",
      "          32       0.00      0.00      0.00         1\n",
      "          33       0.00      0.00      0.00         1\n",
      "          34       0.00      0.00      0.00         1\n",
      "          35       0.00      0.00      0.00         1\n",
      "          36       0.00      0.00      0.00         2\n",
      "          37       0.00      0.00      0.00         3\n",
      "          38       0.00      0.00      0.00         2\n",
      "          39       0.00      0.00      0.00         2\n",
      "          40       0.00      0.00      0.00         3\n",
      "          41       0.00      0.00      0.00         1\n",
      "          42       0.17      0.25      0.20         4\n",
      "          43       0.00      0.00      0.00         1\n",
      "          44       0.00      0.00      0.00         1\n",
      "          45       0.50      0.25      0.33         4\n",
      "          46       0.00      0.00      0.00         3\n",
      "          47       0.00      0.00      0.00         3\n",
      "          48       0.00      0.00      0.00         3\n",
      "          49       0.00      0.00      0.00         1\n",
      "          50       0.00      0.00      0.00         1\n",
      "          51       0.00      0.00      0.00         2\n",
      "          52       0.00      0.00      0.00         2\n",
      "          53       0.14      0.20      0.17         5\n",
      "          54       0.00      0.00      0.00         3\n",
      "          55       0.00      0.00      0.00         2\n",
      "          56       0.00      0.00      0.00         1\n",
      "          57       0.00      0.00      0.00         1\n",
      "          58       0.00      0.00      0.00         2\n",
      "          60       0.00      0.00      0.00         7\n",
      "          62       0.20      0.33      0.25         3\n",
      "          63       0.00      0.00      0.00         3\n",
      "          64       0.33      0.20      0.25         5\n",
      "          65       0.00      0.00      0.00         5\n",
      "          66       0.00      0.00      0.00         6\n",
      "          67       0.08      0.12      0.10         8\n",
      "          68       0.33      0.20      0.25         5\n",
      "          69       0.00      0.00      0.00         2\n",
      "          70       0.00      0.00      0.00         5\n",
      "          71       0.00      0.00      0.00         4\n",
      "          72       0.00      0.00      0.00         1\n",
      "          73       0.00      0.00      0.00         4\n",
      "          74       0.08      0.11      0.09         9\n",
      "          75       0.00      0.00      0.00         1\n",
      "          76       0.00      0.00      0.00         2\n",
      "          77       0.00      0.00      0.00         9\n",
      "          78       0.00      0.00      0.00         9\n",
      "          79       0.00      0.00      0.00         1\n",
      "          80       0.09      0.17      0.12         6\n",
      "          81       0.00      0.00      0.00         3\n",
      "          82       0.00      0.00      0.00         4\n",
      "          83       0.00      0.00      0.00         5\n",
      "          84       0.00      0.00      0.00         7\n",
      "          85       0.15      0.15      0.15        13\n",
      "          86       0.21      0.37      0.26        19\n",
      "          87       0.00      0.00      0.00         7\n",
      "          88       0.00      0.00      0.00         8\n",
      "          89       0.00      0.00      0.00         5\n",
      "          90       0.00      0.00      0.00         1\n",
      "          91       0.00      0.00      0.00         6\n",
      "          92       0.00      0.00      0.00         1\n",
      "          93       0.00      0.00      0.00         4\n",
      "          94       0.00      0.00      0.00        12\n",
      "          95       0.00      0.00      0.00         8\n",
      "          96       0.05      0.04      0.04        24\n",
      "          97       0.15      0.18      0.17        11\n",
      "          98       0.19      0.20      0.19        15\n",
      "          99       0.21      0.25      0.23        20\n",
      "         100       0.00      0.00      0.00         7\n",
      "         101       0.33      0.24      0.28        25\n",
      "         102       0.00      0.00      0.00         9\n",
      "         103       0.14      0.07      0.10        14\n",
      "         104       0.16      0.21      0.18        29\n",
      "         105       0.05      0.06      0.05        16\n",
      "         106       0.15      0.17      0.16        42\n",
      "         107       0.08      0.07      0.07        14\n",
      "         108       0.08      0.06      0.07        16\n",
      "         109       0.22      0.29      0.25         7\n",
      "         110       0.11      0.13      0.12        39\n",
      "         111       0.00      0.00      0.00         7\n",
      "\n",
      "    accuracy                           0.11       558\n",
      "   macro avg       0.06      0.06      0.05       558\n",
      "weighted avg       0.10      0.11      0.10       558\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Step 2e: Predicting Clusters with Logistic Regression\n",
    "# Load cluster labels\n",
    "y_clusters = metadata['clusters']\n",
    "\n",
    "# Count samples in each cluster to check distribution\n",
    "cluster_counts = y_clusters.value_counts()\n",
    "print(\"Cluster counts:\\n\", cluster_counts)\n",
    "\n",
    "# Filter out clusters with fewer than two samples\n",
    "valid_clusters = cluster_counts[cluster_counts >= 2].index\n",
    "X_filtered = X[y_clusters.isin(valid_clusters)]\n",
    "y_clusters_filtered = y_clusters[y_clusters.isin(valid_clusters)]\n",
    "\n",
    "# Confirm the shapes after filtering\n",
    "print(\"Filtered X shape:\", X_filtered.shape)\n",
    "print(\"Filtered y_clusters shape:\", y_clusters_filtered.shape)\n",
    "\n",
    "# Split data for cluster prediction with stratification\n",
    "X_train_cl, X_test_cl, y_train_cl, y_test_cl = train_test_split(\n",
    "    X_filtered, y_clusters_filtered, test_size=0.3, random_state=42, stratify=y_clusters_filtered\n",
    ")\n",
    "\n",
    "# Initialize and train the Logistic Regression model for multi-class prediction\n",
    "logistic_model_clusters = LogisticRegression(random_state=42, multi_class='ovr')\n",
    "logistic_model_clusters.fit(X_train_cl, y_train_cl)\n",
    "print(\"Logistic Regression model trained for cluster prediction.\")\n",
    "\n",
    "# Make predictions and evaluate the model\n",
    "y_pred_clusters = logistic_model_clusters.predict(X_test_cl)\n",
    "y_pred_proba_clusters = logistic_model_clusters.predict_proba(X_test_cl)\n",
    "\n",
    "# Calculate sample-specific AUC scores for each cluster class (one-vs-rest for multi-class)\n",
    "auc_scores_clusters = []\n",
    "for i in range(y_pred_proba_clusters.shape[1]):\n",
    "    # Check if the current class exists in y_test_cl\n",
    "    if (y_test_cl == i).sum() > 0 and (y_test_cl != i).sum() > 0:\n",
    "        auc = roc_auc_score((y_test_cl == i).astype(int), y_pred_proba_clusters[:, i])\n",
    "        auc_scores_clusters.append((i, auc))\n",
    "    else:\n",
    "        auc_scores_clusters.append((i, \"AUC not defined for single-class\"))\n",
    "\n",
    "# Display AUC scores and classification report\n",
    "print(\"Sample-specific AUC Scores for cluster prediction:\", auc_scores_clusters)\n",
    "print(\"Classification Report for Cluster Prediction:\\n\", classification_report(y_test_cl, y_pred_clusters))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Group Prediction Class Counts:\n",
      "          mutated  reference\n",
      "SampleID                    \n",
      "0               0          4\n",
      "1               0          4\n",
      "2               1          3\n",
      "3               0          4\n",
      "4               0          4\n",
      "...           ...        ...\n",
      "561             0          2\n",
      "562             0          2\n",
      "563             0          2\n",
      "564             0          2\n",
      "565             0          2\n",
      "\n",
      "[566 rows x 2 columns]\n",
      "\n",
      "Cluster Prediction Class Counts:\n",
      "          0.0    1.0    2.0    3.0    4.0    5.0    6.0    18.0   28.0   \\\n",
      "SampleID                                                                  \n",
      "0             3      0      0      0      0      0      0      0      0   \n",
      "1             1      0      1      0      0      0      1      0      0   \n",
      "2             3      0      0      0      0      0      0      0      0   \n",
      "3             2      0      0      0      1      0      0      0      0   \n",
      "4             2      0      0      1      0      0      0      0      0   \n",
      "...         ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
      "561           1      0      0      0      0      0      0      0      0   \n",
      "562           1      0      0      0      0      0      0      0      0   \n",
      "563           1      0      0      0      0      0      0      0      0   \n",
      "564           0      0      0      0      0      0      1      0      0   \n",
      "565           1      0      0      0      0      0      0      0      0   \n",
      "\n",
      "          30.0   ...  102.0  103.0  104.0  105.0  106.0  107.0  108.0  109.0  \\\n",
      "SampleID         ...                                                           \n",
      "0             0  ...      0      0      0      0      0      0      0      0   \n",
      "1             0  ...      0      0      0      0      0      1      0      0   \n",
      "2             0  ...      0      0      0      0      1      0      0      0   \n",
      "3             0  ...      0      0      0      0      0      0      1      0   \n",
      "4             0  ...      0      0      0      0      0      0      0      0   \n",
      "...         ...  ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
      "561           0  ...      0      0      0      0      0      0      0      0   \n",
      "562           0  ...      0      0      0      0      0      0      0      0   \n",
      "563           0  ...      0      0      0      0      0      0      0      0   \n",
      "564           0  ...      0      0      0      0      0      0      0      0   \n",
      "565           0  ...      0      0      0      0      0      0      0      0   \n",
      "\n",
      "          110.0  111.0  \n",
      "SampleID                \n",
      "0             0      0  \n",
      "1             0      0  \n",
      "2             0      0  \n",
      "3             0      0  \n",
      "4             0      0  \n",
      "...         ...    ...  \n",
      "561           0      0  \n",
      "562           0      0  \n",
      "563           0      0  \n",
      "564           0      0  \n",
      "565           0      0  \n",
      "\n",
      "[566 rows x 79 columns]\n",
      "\n",
      "Stability Correlation between Group and Cluster Predictions: -0.3662261290497657\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load each prediction file with its specific column name\n",
    "def load_prediction(file_path, pred_col):\n",
    "    df = pd.read_csv(file_path)\n",
    "    if pred_col in df.columns:\n",
    "        return df[pred_col]\n",
    "    else:\n",
    "        print(f\"Warning: Column '{pred_col}' not found in {file_path}.\")\n",
    "        return None\n",
    "\n",
    "# Group prediction columns based on actual column names\n",
    "group_predictions = {\n",
    "    \"Naive Bayes (Group)\": load_prediction(\"naive_bayes_predictions.csv\", \"Predicted\"),\n",
    "    \"KNN (Group)\": load_prediction(\"knn_predictions.csv\", \"predicted\"),\n",
    "    \"Logistic Regression (Group)\": load_prediction(\"LR_group_predictions.csv\", \"Predicted_Label\"),\n",
    "    \"Random Forest (Group)\": load_prediction(\"rf_predictions.csv\", \"Predicted Group\")\n",
    "}\n",
    "\n",
    "# Cluster prediction columns based on actual column names\n",
    "cluster_predictions = {\n",
    "    \"Naive Bayes (Cluster)\": load_prediction(\"naive_bayes_cluster_predictions.csv\", \"Predicted_Cluster\"),\n",
    "    \"KNN (Cluster)\": load_prediction(\"knn_cluster_predictions.csv\", \"predicted_cluster\"),\n",
    "    \"Logistic Regression (Cluster)\": load_prediction(\"LR_cluster_predictions.csv\", \"Predicted_Label\"),\n",
    "    \"Random Forest (Cluster)\": load_prediction(\"rf_cluster_predictions.csv\", \"Predicted Group\")\n",
    "}\n",
    "\n",
    "# Filter out any None values (i.e., files without the specified column)\n",
    "group_predictions = {k: v for k, v in group_predictions.items() if v is not None}\n",
    "cluster_predictions = {k: v for k, v in cluster_predictions.items() if v is not None}\n",
    "\n",
    "# Combine group predictions into a DataFrame and calculate class counts\n",
    "if group_predictions:\n",
    "    group_matrix = pd.DataFrame(group_predictions)\n",
    "    group_matrix.index.name = 'SampleID'\n",
    "    group_class_counts = group_matrix.apply(pd.Series.value_counts, axis=1).fillna(0).astype(int)\n",
    "    group_matrix.to_csv(\"group_prediction_matrix.csv\")\n",
    "    group_class_counts.to_csv(\"group_class_counts.csv\")\n",
    "    print(\"\\nGroup Prediction Class Counts:\")\n",
    "    print(group_class_counts)\n",
    "\n",
    "# Combine cluster predictions into a DataFrame and calculate class counts\n",
    "if cluster_predictions:\n",
    "    cluster_matrix = pd.DataFrame(cluster_predictions)\n",
    "    cluster_matrix.index.name = 'SampleID'\n",
    "    cluster_class_counts = cluster_matrix.apply(pd.Series.value_counts, axis=1).fillna(0).astype(int)\n",
    "    cluster_matrix.to_csv(\"cluster_prediction_matrix.csv\")\n",
    "    cluster_class_counts.to_csv(\"cluster_class_counts.csv\")\n",
    "    print(\"\\nCluster Prediction Class Counts:\")\n",
    "    print(cluster_class_counts)\n",
    "\n",
    "# Optional: calculate correlation if both group and cluster counts are available\n",
    "if 'group_class_counts' in locals() and 'cluster_class_counts' in locals():\n",
    "    combined_counts = group_class_counts.add(cluster_class_counts, fill_value=0)\n",
    "    stability_correlation = combined_counts.corr().iloc[0, 1]\n",
    "    print(\"\\nStability Correlation between Group and Cluster Predictions:\", stability_correlation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of models predicting each class label per sample:\n",
      "SampleID   0    1    2    3    4    5    6    7    8    9    ...  556  557  \\\n",
      "mutated      0    0    1    0    0    0    1    0    0    0  ...    0    0   \n",
      "reference    4    4    3    4    4    4    3    4    4    4  ...    2    2   \n",
      "\n",
      "SampleID   558  559  560  561  562  563  564  565  \n",
      "mutated      0    0    0    0    0    0    0    0  \n",
      "reference    2    2    2    2    2    2    2    2  \n",
      "\n",
      "[2 rows x 566 columns]\n",
      "\n",
      "Number of models predicting the same cluster per sample:\n",
      "SampleID  0    1    2    3    4    5    6    7    8    9    ...  556  557  \\\n",
      "0.0         3    1    3    2    2    3    2    3    3    1  ...    0    0   \n",
      "1.0         0    0    0    0    0    0    0    0    0    1  ...    0    0   \n",
      "2.0         0    1    0    0    0    0    0    0    0    0  ...    0    0   \n",
      "3.0         0    0    0    0    1    0    0    0    0    1  ...    1    1   \n",
      "4.0         0    0    0    1    0    0    1    0    0    0  ...    0    0   \n",
      "...       ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
      "107.0       0    1    0    0    0    0    0    0    0    0  ...    0    0   \n",
      "108.0       0    0    0    1    0    0    0    0    0    0  ...    0    0   \n",
      "109.0       0    0    0    0    0    0    0    0    0    0  ...    0    0   \n",
      "110.0       0    0    0    0    0    1    0    0    1    0  ...    0    0   \n",
      "111.0       0    0    0    0    0    0    0    0    0    0  ...    0    0   \n",
      "\n",
      "SampleID  558  559  560  561  562  563  564  565  \n",
      "0.0         1    1    0    1    1    1    0    1  \n",
      "1.0         0    0    0    0    0    0    0    0  \n",
      "2.0         0    0    0    0    0    0    0    0  \n",
      "3.0         0    0    1    0    0    0    0    0  \n",
      "4.0         0    0    0    0    0    0    0    0  \n",
      "...       ...  ...  ...  ...  ...  ...  ...  ...  \n",
      "107.0       0    0    0    0    0    0    0    0  \n",
      "108.0       0    0    0    0    0    0    0    0  \n",
      "109.0       0    0    0    0    0    0    0    0  \n",
      "110.0       0    0    0    0    0    0    0    0  \n",
      "111.0       0    0    0    0    0    0    0    0  \n",
      "\n",
      "[79 rows x 566 columns]\n",
      "\n",
      "Stability Correlation between Group and Cluster Predictions: 1.00\n",
      "Corrected p-value: 0.0000\n",
      "The stability of the cluster and class label prediction is significantly correlated.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "\n",
    "# A. How many models predict each class label, for each sample?\n",
    "group_class_counts = group_class_counts.T\n",
    "print(\"\\nNumber of models predicting each class label per sample:\")\n",
    "print(group_class_counts)\n",
    "\n",
    "# B. How many models predict the same cluster, for each sample? \n",
    "cluster_class_counts = cluster_class_counts.T \n",
    "print(\"\\nNumber of models predicting the same cluster per sample:\")\n",
    "print(cluster_class_counts)\n",
    "\n",
    "# C. Does the stability of the cluster and class label prediction correlate?\n",
    "if 'group_class_counts' in locals() and 'cluster_class_counts' in locals():\n",
    "    # Combine the class and cluster counts into a single DataFrame\n",
    "    combined_counts = pd.concat([group_class_counts, cluster_class_counts], axis=1)\n",
    "    \n",
    "    # Calculate the Pearson correlation coefficient\n",
    "    stability_correlation, p_value = pearsonr(combined_counts.sum(axis=1), combined_counts.sum(axis=1, numeric_only=True))\n",
    "    \n",
    "    # Apply Bonferroni correction for multiple tests\n",
    "    alpha = 0.05\n",
    "    corrected_p_value = p_value * 2  # Bonferroni correction for 2 tests\n",
    "    \n",
    "    print(f\"\\nStability Correlation between Group and Cluster Predictions: {stability_correlation:.2f}\")\n",
    "    print(f\"Corrected p-value: {corrected_p_value:.4f}\")\n",
    "    \n",
    "    if corrected_p_value < alpha:\n",
    "        print(\"The stability of the cluster and class label prediction is significantly correlated.\")\n",
    "    else:\n",
    "        print(\"The stability of the cluster and class label prediction is not significantly correlated.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating models with top 10 genes:\n",
      "Insufficient samples for 10 genes. Skipping.\n",
      "Insufficient samples for 10 genes. Skipping.\n",
      "Insufficient samples for 10 genes. Skipping.\n",
      "Insufficient samples for 10 genes. Skipping.\n",
      "\n",
      "Evaluating models with top 100 genes:\n",
      "Naive Bayes AUC for top 100 genes: 0.8571428571428572\n",
      "KNN AUC for top 100 genes: 0.9813664596273293\n",
      "Logistic Regression AUC for top 100 genes: 1.0\n",
      "Random Forest AUC for top 100 genes: 1.0\n",
      "\n",
      "Evaluating models with top 1000 genes:\n",
      "Naive Bayes AUC for top 1000 genes: 0.5943396226415094\n",
      "KNN AUC for top 1000 genes: 0.9947169811320755\n",
      "Logistic Regression AUC for top 1000 genes: 0.9918059299191375\n",
      "Random Forest AUC for top 1000 genes: 1.0\n",
      "\n",
      "Evaluating models with top 10000 genes:\n",
      "Naive Bayes AUC for top 10000 genes: 0.5562368972746331\n",
      "KNN AUC for top 10000 genes: 0.9973794549266247\n",
      "Logistic Regression AUC for top 10000 genes: 1.0\n",
      "Random Forest AUC for top 10000 genes: 1.0\n",
      "\n",
      "Summary of AUC Scores by Gene Count and Model:\n",
      "       Naive Bayes       KNN  Logistic Regression  Random Forest\n",
      "100       0.857143  0.981366             1.000000            1.0\n",
      "1000      0.594340  0.994717             0.991806            1.0\n",
      "10000     0.556237  0.997379             1.000000            1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load data\n",
    "expression_data = pd.read_csv('ERP009868.tsv', sep='\\t', index_col=0)\n",
    "metadata = pd.read_csv('metadata_ERP009868.tsv', sep='\\t')\n",
    "\n",
    "# Create mutation status column if it doesn't exist\n",
    "if 'mutation_status' not in metadata.columns:\n",
    "    metadata['mutation_status'] = metadata['refinebio_title'].apply(lambda x: 'reference' if x == 'Danio rerio' else 'mutant')\n",
    "\n",
    "# Define models including Adam's Random Forest\n",
    "naive_bayes_model = GaussianNB()\n",
    "knn_model = KNeighborsClassifier(n_neighbors=5)\n",
    "logistic_model = LogisticRegression(random_state=42, max_iter=1000)\n",
    "rf_model = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Store AUC scores\n",
    "auc_scores = {\n",
    "    'Naive Bayes': {},\n",
    "    'KNN': {},\n",
    "    'Logistic Regression': {},\n",
    "    'Random Forest': {}\n",
    "}\n",
    "\n",
    "# Helper function to retrain and evaluate models\n",
    "def retrain_and_evaluate(model, model_name, gene_count):\n",
    "    top_genes = expression_data.var(axis=0).nlargest(gene_count).index\n",
    "    subset_data = expression_data[top_genes].T\n",
    "    subset_data.index.name = 'refinebio_accession_code'\n",
    "    merged_data = subset_data.merge(metadata[['refinebio_accession_code', 'mutation_status']],\n",
    "                                    left_index=True,\n",
    "                                    right_on='refinebio_accession_code', how='inner')\n",
    "\n",
    "    if merged_data.empty:\n",
    "        print(f\"No matching samples for gene count {gene_count}.\")\n",
    "        return\n",
    "\n",
    "    X = merged_data.drop(columns=['refinebio_accession_code', 'mutation_status'])\n",
    "    y = merged_data['mutation_status'].apply(lambda x: 1 if x == 'mutant' else 0)\n",
    "\n",
    "    if (y.value_counts() < 2).any():\n",
    "        print(f\"Insufficient samples for {gene_count} genes. Skipping.\")\n",
    "        return\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred_proba = model.predict_proba(X_test)[:, 1] if hasattr(model, \"predict_proba\") else model.decision_function(X_test)\n",
    "    auc_score = roc_auc_score(y_test, y_pred_proba)\n",
    "    auc_scores[model_name][gene_count] = auc_score\n",
    "    print(f\"{model_name} AUC for top {gene_count} genes: {auc_score}\")\n",
    "\n",
    "# Evaluate each model\n",
    "gene_counts = [10, 100, 1000, 10000]\n",
    "for n in gene_counts:\n",
    "    print(f\"\\nEvaluating models with top {n} genes:\")\n",
    "    retrain_and_evaluate(naive_bayes_model, 'Naive Bayes', n)\n",
    "    retrain_and_evaluate(knn_model, 'KNN', n)\n",
    "    retrain_and_evaluate(logistic_model, 'Logistic Regression', n)\n",
    "    retrain_and_evaluate(rf_model, 'Random Forest', n)\n",
    "\n",
    "# Summarize AUC results\n",
    "auc_summary = pd.DataFrame(auc_scores)\n",
    "print(\"\\nSummary of AUC Scores by Gene Count and Model:\")\n",
    "print(auc_summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/seaborn/matrix.py:560: UserWarning: Clustering large matrix with scipy. Installing `fastcluster` may give better performance.\n",
      "  warnings.warn(msg)\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/seaborn/matrix.py:560: UserWarning: Clustering large matrix with scipy. Installing `fastcluster` may give better performance.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Heatmap Generation Summary:\n",
      "Total number of genes: 10000\n",
      "Number of samples: 1886\n",
      "\n",
      "Sample group counts:\n",
      "reference: 1766\n",
      "mutated: 120\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1500x1200 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Load the expression data\n",
    "expression_data = pd.read_csv('ERP009868.tsv', sep='\\t', index_col=0)\n",
    "\n",
    "# Load the metadata\n",
    "metadata = pd.read_csv('metadata_ERP009868.tsv', sep='\\t')\n",
    "\n",
    "# Create a dictionary to map sample names to their group\n",
    "sample_to_group = {row['refinebio_accession_code']: 'reference' if row['refinebio_title'] == 'Danio rerio' else 'mutated' \n",
    "                   for _, row in metadata.iterrows()}\n",
    "\n",
    "# Get the most variable genes for each model size\n",
    "def get_variable_genes(data, n_genes):\n",
    "    variances = data.var(axis=1).sort_values(ascending=False)\n",
    "    return variances.head(n_genes).index.tolist()\n",
    "\n",
    "# Collect genes from different model sizes\n",
    "all_genes = []\n",
    "for n_genes in [10, 100, 1000, 10000]:\n",
    "    genes = get_variable_genes(expression_data, n_genes)\n",
    "    all_genes.extend(genes)\n",
    "\n",
    "# Remove duplicates while maintaining order\n",
    "all_genes = list(dict.fromkeys(all_genes))\n",
    "\n",
    "# Create expression matrix for selected genes\n",
    "log2_expression = np.log2(expression_data.loc[all_genes] + 1)\n",
    "\n",
    "# Create a color mapping\n",
    "color_map = {'reference': '#2ecc71', 'mutated': '#e74c3c'}  # Green for reference, Red for mutated\n",
    "\n",
    "# Create a color list for the columns\n",
    "col_colors = [color_map[sample_to_group[sample]] for sample in log2_expression.columns]\n",
    "\n",
    "# Create the main figure\n",
    "plt.figure(figsize=(15, 12))\n",
    "\n",
    "# Plot the heatmap with dendrograms and side color bar\n",
    "g = sns.clustermap(log2_expression, \n",
    "                   cmap='RdBu_r',\n",
    "                   col_colors=col_colors,\n",
    "                   col_cluster=True,  # Enable column clustering\n",
    "                   row_cluster=True,  # Enable row clustering\n",
    "                   cbar_kws={'label': 'Log2 Expression'},\n",
    "                   yticklabels=True,\n",
    "                   xticklabels=True,\n",
    "                   dendrogram_ratio=(.1, .2),\n",
    "                   figsize=(15, 12))\n",
    "\n",
    "# Rotate x-axis labels\n",
    "plt.setp(g.ax_heatmap.get_xticklabels(), rotation=45, ha='right')\n",
    "\n",
    "# Add a legend\n",
    "legend_elements = [plt.Rectangle((0,0), 1, 1, facecolor=color_map[label], label=label.capitalize())\n",
    "                  for label in color_map]\n",
    "g.fig.legend(handles=legend_elements,\n",
    "            title='Sample Groups',\n",
    "            loc='center left',\n",
    "            bbox_to_anchor=(1, 0.5))\n",
    "\n",
    "# Set the title\n",
    "g.fig.suptitle('Gene Expression Heatmap of Predictive Modeling Signatures', \n",
    "               fontsize=16, y=1.02)\n",
    "\n",
    "# Add axis labels\n",
    "g.ax_heatmap.set_xlabel('Samples', fontsize=12)\n",
    "g.ax_heatmap.set_ylabel('Genes', fontsize=12)\n",
    "\n",
    "# Adjust the layout and save the figure\n",
    "plt.tight_layout()\n",
    "plt.savefig('predictive_signatures_heatmap.png', dpi=300, bbox_inches='tight')\n",
    "plt.close()\n",
    "\n",
    "# Print summary statistics\n",
    "print('\\nHeatmap Generation Summary:')\n",
    "print(f\"Total number of genes: {len(all_genes)}\")\n",
    "print(f\"Number of samples: {log2_expression.shape[1]}\")\n",
    "print(\"\\nSample group counts:\")\n",
    "group_counts = pd.Series(sample_to_group.values()).value_counts()\n",
    "for group, count in group_counts.items():\n",
    "    print(f\"{group}: {count}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
