{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from scipy.stats import spearmanr\n",
    "import statsmodels.stats.multitest as smm\n",
    "from scipy.stats import pearsonr\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the TSV file\n",
    "expression_path = 'ERP009868.tsv'\n",
    "expression_data = pd.read_csv(expression_path, sep='\\t', index_col=0)\n",
    "\n",
    "# Load your metadata (assuming it's also a CSV file)\n",
    "metadata_path = 'updated_metadata_ERP009868.tsv'\n",
    "metadata = pd.read_csv(metadata_path, sep='\\t', index_col=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "expression_data = expression_data.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate variances for each gene (row) across samples in the expression data\n",
    "variances = expression_data.var(axis=0)  # Use axis=1 if genes are rows\n",
    "\n",
    "# Select the indices of the top 5,000 most variable genes\n",
    "top_genes = variances.nlargest(5000).index\n",
    "\n",
    "# Subset expression_data to include only the 5,000 most variable genes\n",
    "expression_data_subset = expression_data[top_genes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge data and metadata on common identifier\n",
    "expression_data_subset.index.name = 'SampleID'  # Set the name of the index to match the metadata\n",
    "\n",
    "# Reset index of metadata to have sample names as a column\n",
    "metadata_reset = metadata.reset_index().rename(columns={'refinebio_accession_code': 'SampleID'})\n",
    "\n",
    "# Merge expression data with metadata on 'SampleID'\n",
    "data = expression_data_subset.merge(metadata_reset, on='SampleID')\n",
    "\n",
    "# Create 'mutation_status' column based on 'refinebio_title'\n",
    "data['mutation_status'] = data['refinebio_title'].apply(\n",
    "    lambda x: 'reference' if x == 'Danio rerio' else 'mutated'\n",
    ")\n",
    "\n",
    "X = data.drop(columns=['mutation_status'])  # Drop target column; keep gene data\n",
    "y = data['mutation_status']  # Target variable (e.g., tumor vs normal or clusters)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2b: Split data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(expression_data_subset, y, test_size=0.3, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "     mutated       0.33      0.18      0.23        34\n",
      "   reference       0.95      0.98      0.96       532\n",
      "\n",
      "    accuracy                           0.93       566\n",
      "   macro avg       0.64      0.58      0.60       566\n",
      "weighted avg       0.91      0.93      0.92       566\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Step 2c: Train Naive Bayes model\n",
    "nb_model = GaussianNB()\n",
    "nb_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on test set and evaluate\n",
    "y_pred = nb_model.predict(X_test)\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the classification report as a dictionary\n",
    "report_dict = classification_report(y_test, y_pred, output_dict=True)\n",
    "\n",
    "# Convert the dictionary to a DataFrame\n",
    "report_df = pd.DataFrame(report_dict).transpose()\n",
    "\n",
    "# Save the DataFrame as a CSV file\n",
    "report_df.to_csv('classification_report_naive_bayes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions saved to 'naive_bayes_predictions.csv'\n"
     ]
    }
   ],
   "source": [
    "# Convert predictions to a DataFrame\n",
    "y_pred_df = pd.DataFrame(y_pred, columns=['Predicted'])\n",
    "\n",
    "# Optionally, include the actual labels from y_test for comparison\n",
    "y_pred_df['Actual'] = y_test.values  # assuming y_test is a pandas Series or NumPy array\n",
    "\n",
    "# Save to a CSV file\n",
    "y_pred_df.to_csv('naive_bayes_predictions.csv', index=False)\n",
    "\n",
    "print(\"Predictions saved to 'naive_bayes_predictions.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.97      0.96       326\n",
      "           1       1.00      1.00      1.00         6\n",
      "           2       0.57      1.00      0.73         4\n",
      "           3       0.99      0.90      0.94       140\n",
      "           4       0.80      0.82      0.81        39\n",
      "           5       1.00      0.50      0.67         4\n",
      "           6       0.87      1.00      0.93        47\n",
      "\n",
      "    accuracy                           0.94       566\n",
      "   macro avg       0.88      0.88      0.86       566\n",
      "weighted avg       0.94      0.94      0.94       566\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Step 2e: Repeat with clusters as the target if applicable\n",
    "# Assuming 'Clusters' column in metadata\n",
    "y_clusters = data['Clusters']\n",
    "X_train, X_test, y_train, y_test = train_test_split(expression_data_subset, y_clusters, test_size=0.3, random_state=42)\n",
    "nb_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate for clusters\n",
    "y_pred_clusters = nb_model.predict(X_test)\n",
    "print(\"Cluster Classification Report:\\n\", classification_report(y_test, y_pred_clusters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the cluster classification report as a dictionary\n",
    "cluster_report_dict = classification_report(y_test, y_pred_clusters, output_dict=True)\n",
    "\n",
    "# Convert the dictionary to a DataFrame\n",
    "cluster_report_df = pd.DataFrame(cluster_report_dict).transpose()\n",
    "\n",
    "# Save the DataFrame as a CSV file\n",
    "cluster_report_df.to_csv('cluster_classification_report_naive_bayes.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster predictions saved to 'naive_bayes_cluster_predictions.csv'\n"
     ]
    }
   ],
   "source": [
    "# Convert cluster predictions to a DataFrame\n",
    "y_pred_clusters_df = pd.DataFrame(y_pred_clusters, columns=['Predicted_Cluster'])\n",
    "\n",
    "# Optionally, include the actual cluster labels from y_test for comparison\n",
    "y_pred_clusters_df['Actual_Cluster'] = y_test.values  # assuming y_test is a pandas Series or NumPy array\n",
    "\n",
    "# Save to a CSV file\n",
    "y_pred_clusters_df.to_csv('naive_bayes_cluster_predictions.csv', index=False)\n",
    "\n",
    "print(\"Cluster predictions saved to 'naive_bayes_cluster_predictions.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the expression data and metadata\n",
    "expression_path = 'ERP009868.tsv'\n",
    "expression_data = pd.read_csv(expression_path, sep='\\t', index_col=0)\n",
    "\n",
    "metadata_path = 'updated_metadata_ERP009868.tsv'\n",
    "metadata = pd.read_csv(metadata_path, sep='\\t', index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load each prediction file with its specific column name\n",
    "def load_prediction(file_path, pred_col):\n",
    "    df = pd.read_csv(file_path)\n",
    "    if pred_col in df.columns:\n",
    "        return df[pred_col]\n",
    "    else:\n",
    "        print(f\"Warning: Column '{pred_col}' not found in {file_path}.\")\n",
    "        return None\n",
    "\n",
    "# Group prediction columns based on actual column names\n",
    "group_predictions = {\n",
    "    \"Naive Bayes (Group)\": load_prediction(\"naive_bayes_predictions.csv\", \"Predicted\"),\n",
    "    \"KNN (Group)\": load_prediction(\"knn_predictions.csv\", \"predicted\"),\n",
    "    \"Logistic Regression (Group)\": load_prediction(\"logistic_regression_predictions.csv\", \"Predicted_Label\"),\n",
    "    \"Random Forest (Group)\": load_prediction(\"rf_predictions.csv\", \"Predicted Group\")\n",
    "}\n",
    "\n",
    "# Cluster prediction columns based on actual column names\n",
    "cluster_predictions = {\n",
    "    \"Naive Bayes (Cluster)\": load_prediction(\"naive_bayes_cluster_predictions.csv\", \"Predicted_Cluster\"),\n",
    "    \"KNN (Cluster)\": load_prediction(\"knn_cluster_predictions.csv\", \"predicted_cluster\"),\n",
    "    \"Logistic Regression (Cluster)\": load_prediction(\"logistic_regression_cluster_predictions.csv\", \"Predicted_Label\"),\n",
    "    \"Random Forest (Cluster)\": load_prediction(\"rf_cluster_predictions.csv\", \"Predicted Group\")\n",
    "}\n",
    "\n",
    "# Filter out any None values (i.e., files without the specified column)\n",
    "group_predictions = {k: v for k, v in group_predictions.items() if v is not None}\n",
    "cluster_predictions = {k: v for k, v in cluster_predictions.items() if v is not None}\n",
    "\n",
    "# Convert group and cluster predictions dictionaries to DataFrames\n",
    "group_predictions_df = pd.DataFrame(group_predictions)\n",
    "cluster_predictions_df = pd.DataFrame(cluster_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of models predicting each class label per sample:\n",
      "     mutated  reference\n",
      "0        0.0        4.0\n",
      "1        0.0        4.0\n",
      "2        1.0        3.0\n",
      "3        0.0        4.0\n",
      "4        0.0        4.0\n",
      "..       ...        ...\n",
      "561      0.0        2.0\n",
      "562      0.0        2.0\n",
      "563      0.0        2.0\n",
      "564      0.0        2.0\n",
      "565      0.0        2.0\n",
      "\n",
      "[566 rows x 2 columns]\n",
      "\n",
      "Number of models predicting the same cluster per sample:\n",
      "     0.0    1.0    2.0    3.0    4.0    5.0    6.0    18.0   28.0   30.0   \\\n",
      "0      3.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
      "1      1.0    0.0    1.0    0.0    0.0    0.0    1.0    0.0    0.0    0.0   \n",
      "2      3.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
      "3      2.0    0.0    0.0    0.0    1.0    0.0    0.0    0.0    0.0    0.0   \n",
      "4      2.0    0.0    0.0    1.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
      "..     ...    ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
      "561    1.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
      "562    1.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
      "563    1.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
      "564    0.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0    0.0    0.0   \n",
      "565    1.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
      "\n",
      "     ...  102.0  103.0  104.0  105.0  106.0  107.0  108.0  109.0  110.0  111.0  \n",
      "0    ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
      "1    ...    0.0    0.0    0.0    0.0    0.0    1.0    0.0    0.0    0.0    0.0  \n",
      "2    ...    0.0    0.0    0.0    0.0    1.0    0.0    0.0    0.0    0.0    0.0  \n",
      "3    ...    0.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0    0.0    0.0  \n",
      "4    ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
      "..   ...    ...    ...    ...    ...    ...    ...    ...    ...    ...    ...  \n",
      "561  ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
      "562  ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
      "563  ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
      "564  ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
      "565  ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
      "\n",
      "[566 rows x 79 columns]\n",
      "\n",
      "Stability Correlation between Group and Cluster Predictions: 0.59\n",
      "Corrected p-value: 0.0000\n",
      "The stability of the cluster and class label prediction is significantly correlated.\n"
     ]
    }
   ],
   "source": [
    "# Part 3a: Calculate how many models predict each class label for each sample\n",
    "class_counts = group_predictions_df.apply(lambda row: row.value_counts(), axis=1).fillna(0)\n",
    "print(\"Number of models predicting each class label per sample:\")\n",
    "print(class_counts)\n",
    "\n",
    "# Part 3b: Calculate how many models predict the same cluster for each sample\n",
    "# Assuming clusters are represented as integers, similar to class labels\n",
    "# This can be the same as class_counts if we're looking for majority class in each row\n",
    "cluster_counts = cluster_predictions_df.apply(lambda row: row.value_counts(), axis=1).fillna(0)\n",
    "print(\"\\nNumber of models predicting the same cluster per sample:\")\n",
    "print(cluster_counts)\n",
    "\n",
    "# Part 3c: Correlation between stability of cluster and class label prediction\n",
    "# Calculate the stability score as the maximum count for any predicted label (most common prediction)\n",
    "# For each row (sample), take the highest value in `class_counts` and `cluster_counts`\n",
    "\n",
    "class_stability = class_counts.max(axis=1)\n",
    "cluster_stability = cluster_counts.max(axis=1)\n",
    "\n",
    "# Calculate Pearson correlation between class and cluster stability\n",
    "stability_correlation, p_value = pearsonr(class_stability, cluster_stability)\n",
    "\n",
    "# Apply Bonferroni correction for multiple tests\n",
    "alpha = 0.05\n",
    "corrected_p_value = p_value * 2  # Bonferroni correction for 2 tests\n",
    "\n",
    "print(f\"\\nStability Correlation between Group and Cluster Predictions: {stability_correlation:.2f}\")\n",
    "print(f\"Corrected p-value: {corrected_p_value:.4f}\")\n",
    "\n",
    "if corrected_p_value < alpha:\n",
    "    print(\"The stability of the cluster and class label prediction is significantly correlated.\")\n",
    "else:\n",
    "    print(\"The stability of the cluster and class label prediction is not significantly correlated.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert non-numeric columns to numeric\n",
    "expression_data = expression_data.select_dtypes(include=['number']).copy()\n",
    "\n",
    "# Create sample to group mapping\n",
    "sample_to_group = {}\n",
    "for _, row in metadata.iterrows():\n",
    "    sample_name = row['refinebio_accession_code']\n",
    "    if row['refinebio_title'] == \"Danio rerio\":\n",
    "        sample_to_group[sample_name] = 'reference'\n",
    "    else:\n",
    "        sample_to_group[sample_name] = 'mutated'\n",
    "\n",
    "# Function to train Naive Bayes model with specified number of genes\n",
    "def train_and_evaluate(n_genes):\n",
    "    # Select the n most variable genes\n",
    "    var_genes = expression_data.std(axis=1).sort_values(ascending=False).head(n_genes).index\n",
    "    expression_subset = expression_data.loc[var_genes]\n",
    "    \n",
    "    # Prepare the data\n",
    "    X = expression_subset.T\n",
    "    y = [sample_to_group[sample] for sample in X.index]\n",
    "    \n",
    "    # Split the data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Train and evaluate Naive Bayes model\n",
    "    nb_model = GaussianNB()\n",
    "    nb_model.fit(X_train, y_train)\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    accuracy = nb_model.score(X_test, y_test)\n",
    "    \n",
    "    # Calculate AUC\n",
    "    y_pred_proba = nb_model.predict_proba(X_test)\n",
    "    y_test_binary = [1 if label == 'mutated' else 0 for label in y_test]\n",
    "    auc = roc_auc_score(y_test_binary, y_pred_proba[:, 1])\n",
    "    \n",
    "    # Save predictions\n",
    "    y_pred = nb_model.predict(X_test)\n",
    "    predictions_df = pd.DataFrame({\n",
    "        'predicted': y_pred,\n",
    "        'actual': y_test,\n",
    "        'prob_mutated': y_pred_proba[:, 1]\n",
    "    }, index=X_test.index)\n",
    "    predictions_df.to_csv(f'predictions_{n_genes}_genes.csv')\n",
    "    \n",
    "    return accuracy, auc\n",
    "\n",
    "# Test different numbers of genes\n",
    "gene_numbers = [10, 100, 1000, 10000]\n",
    "results = []\n",
    "\n",
    "for n_genes in gene_numbers:\n",
    "    accuracy, auc = train_and_evaluate(n_genes)\n",
    "    results.append({\n",
    "        'n_genes': n_genes,\n",
    "        'accuracy': accuracy,\n",
    "        'auc': auc  # Directly store the AUC without modification\n",
    "    })\n",
    "\n",
    "# Create results DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df.to_csv('gene_number_results.csv')\n",
    "\n",
    "# Plot the results\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(results_df['n_genes'], results_df['auc'], marker='o', label='AUC')\n",
    "plt.plot(results_df['n_genes'], results_df['accuracy'], marker='s', label='Accuracy')\n",
    "plt.xscale('log')\n",
    "plt.xlabel('Number of Genes')\n",
    "plt.ylabel('Score')\n",
    "plt.title('Naive Bayes Performance vs Number of Genes')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.savefig('performance_vs_genes.png')\n",
    "plt.close()\n",
    "\n",
    "# Print results\n",
    "print(\"\\nResults Summary:\")\n",
    "print(results_df.to_string(index=False))\n",
    "\n",
    "# Calculate performance changes\n",
    "print(\"\\nPerformance Changes:\")\n",
    "for i in range(1, len(gene_numbers)):\n",
    "    prev_genes = gene_numbers[i-1]\n",
    "    curr_genes = gene_numbers[i]\n",
    "    auc_change = results_df.iloc[i]['auc'] - results_df.iloc[i-1]['auc']\n",
    "    print(f\"\\nFrom {prev_genes} to {curr_genes} genes:\")\n",
    "    print(f\"AUC change: {auc_change:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\david\\AppData\\Roaming\\Python\\Python312\\site-packages\\seaborn\\matrix.py:560: UserWarning: Clustering large matrix with scipy. Installing `fastcluster` may give better performance.\n",
      "  warnings.warn(msg)\n",
      "C:\\Users\\david\\AppData\\Roaming\\Python\\Python312\\site-packages\\seaborn\\matrix.py:560: UserWarning: Clustering large matrix with scipy. Installing `fastcluster` may give better performance.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Heatmap Generation Summary:\n",
      "Total number of genes: 10000\n",
      "Number of samples: 1886\n",
      "\n",
      "Sample group counts:\n",
      "reference: 1766\n",
      "mutated: 120\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1500x1200 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load the expression data\n",
    "expression_data = pd.read_csv('ERP009868.tsv', sep='\\t', index_col=0)\n",
    "\n",
    "# Load the metadata\n",
    "metadata = pd.read_csv('metadata_ERP009868.tsv', sep='\\t')\n",
    "\n",
    "# Create a dictionary to map sample names to their group\n",
    "sample_to_group = {row['refinebio_accession_code']: 'reference' if row['refinebio_title'] == 'Danio rerio' else 'mutated' \n",
    "                   for _, row in metadata.iterrows()}\n",
    "\n",
    "# Get the most variable genes for each model size\n",
    "def get_variable_genes(data, n_genes):\n",
    "    variances = data.var(axis=1).sort_values(ascending=False)\n",
    "    return variances.head(n_genes).index.tolist()\n",
    "\n",
    "# Collect genes from different model sizes\n",
    "all_genes = []\n",
    "for n_genes in [10, 100, 1000, 10000]:\n",
    "    genes = get_variable_genes(expression_data, n_genes)\n",
    "    all_genes.extend(genes)\n",
    "\n",
    "# Remove duplicates while maintaining order\n",
    "all_genes = list(dict.fromkeys(all_genes))\n",
    "\n",
    "# Create expression matrix for selected genes\n",
    "log2_expression = np.log2(expression_data.loc[all_genes] + 1)\n",
    "\n",
    "# Create a color mapping\n",
    "color_map = {'reference': '#2ecc71', 'mutated': '#e74c3c'}  # Green for reference, Red for mutated\n",
    "\n",
    "# Create a color list for the columns\n",
    "col_colors = [color_map[sample_to_group[sample]] for sample in log2_expression.columns]\n",
    "\n",
    "# Create the main figure\n",
    "plt.figure(figsize=(15, 12))\n",
    "\n",
    "# Plot the heatmap with dendrograms and side color bar\n",
    "g = sns.clustermap(log2_expression, \n",
    "                   cmap='RdBu_r',\n",
    "                   col_colors=col_colors,\n",
    "                   col_cluster=True,  # Enable column clustering\n",
    "                   row_cluster=True,  # Enable row clustering\n",
    "                   cbar_kws={'label': 'Log2 Expression'},\n",
    "                   yticklabels=True,\n",
    "                   xticklabels=True,\n",
    "                   dendrogram_ratio=(.1, .2),\n",
    "                   figsize=(15, 12))\n",
    "\n",
    "# Rotate x-axis labels\n",
    "plt.setp(g.ax_heatmap.get_xticklabels(), rotation=45, ha='right')\n",
    "\n",
    "# Add a legend\n",
    "legend_elements = [plt.Rectangle((0,0), 1, 1, facecolor=color_map[label], label=label.capitalize())\n",
    "                  for label in color_map]\n",
    "g.fig.legend(handles=legend_elements,\n",
    "            title='Sample Groups',\n",
    "            loc='center left',\n",
    "            bbox_to_anchor=(1, 0.5))\n",
    "\n",
    "# Set the title\n",
    "g.fig.suptitle('Gene Expression Heatmap of Predictive Modeling Signatures', \n",
    "               fontsize=16, y=1.02)\n",
    "\n",
    "# Add axis labels\n",
    "g.ax_heatmap.set_xlabel('Samples', fontsize=12)\n",
    "g.ax_heatmap.set_ylabel('Genes', fontsize=12)\n",
    "\n",
    "# Adjust the layout and save the figure\n",
    "plt.tight_layout()\n",
    "plt.savefig('predictive_signatures_heatmap.png', dpi=300, bbox_inches='tight')\n",
    "plt.close()\n",
    "\n",
    "# Print summary statistics\n",
    "print('\\nHeatmap Generation Summary:')\n",
    "print(f\"Total number of genes: {len(all_genes)}\")\n",
    "print(f\"Number of samples: {log2_expression.shape[1]}\")\n",
    "print(\"\\nSample group counts:\")\n",
    "group_counts = pd.Series(sample_to_group.values()).value_counts()\n",
    "for group, count in group_counts.items():\n",
    "    print(f\"{group}: {count}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
